{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "794f9aa9",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# Residual-based Adaptive Sampling for PINNs\n",
    "\n",
    "This example demonstrates how to use Residual-based Adaptive Distribution (RAD)\n",
    "sampling for more efficient PINN training. RAD concentrates collocation points\n",
    "in regions with high PDE residual.\n",
    "\n",
    "**Key Concepts:**\n",
    "- Residual-weighted sampling distribution\n",
    "- Adaptive collocation point refinement (RAR-D)\n",
    "- Comparison with uniform sampling\n",
    "\n",
    "**SciML Context:**\n",
    "PINNs with uniform collocation point distributions often struggle with\n",
    "solutions that have localized features (sharp gradients, boundary layers).\n",
    "Adaptive sampling focuses computational effort where it's needed most.\n",
    "\n",
    "**Reference Implementation:**\n",
    "Based on DeepXDE's Residual-based Adaptive Refinement (RAR) algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d91ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "SEED = 42\n",
    "N_INITIAL_POINTS = 200\n",
    "N_UNIFORM_POINTS = 400  # Total for uniform baseline\n",
    "REFINE_FREQUENCY = 200\n",
    "N_REFINE_POINTS = 50\n",
    "LEARNING_RATE = 1e-3\n",
    "TRAINING_STEPS = 1000\n",
    "\n",
    "# Output directory\n",
    "OUTPUT_DIR = \"docs/assets/examples/adaptive_sampling\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4570d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"Opifex Example: Residual-based Adaptive Sampling\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29c0624",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import optax\n",
    "from flax import nnx\n",
    "\n",
    "\n",
    "print(f\"JAX backend: {jax.default_backend()}\")\n",
    "print(f\"JAX devices: {jax.devices()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0481d6",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from opifex.core.training.components.adaptive_sampling import (\n",
    "    RADConfig,\n",
    "    RADSampler,\n",
    "    RARDConfig,\n",
    "    RARDRefiner,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cad9113",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Step 1: Define the Problem\n",
    "\n",
    "We solve the Burgers equation with a shock-like solution:\n",
    "    u_t + u * u_x = nu * u_xx on [0, 2*pi] x [0, 1]\n",
    "    u(x, 0) = -sin(x)\n",
    "    u(0, t) = u(2*pi, t) = 0 (periodic-like)\n",
    "\n",
    "The solution develops a steep gradient (quasi-shock) that requires\n",
    "high resolution to capture accurately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6a8dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BurgersPINN(nnx.Module):\n",
    "    \"\"\"PINN for 1D Burgers equation.\"\"\"\n",
    "\n",
    "    def __init__(self, hidden_dims: list[int] | None = None, *, rngs: nnx.Rngs):\n",
    "        super().__init__()\n",
    "        if hidden_dims is None:\n",
    "            hidden_dims = [32, 32, 32]\n",
    "        layers = []\n",
    "        in_dim = 2  # x, t\n",
    "\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.append(nnx.Linear(in_dim, hidden_dim, rngs=rngs))\n",
    "            in_dim = hidden_dim\n",
    "\n",
    "        layers.append(nnx.Linear(in_dim, 1, rngs=rngs))\n",
    "        self.layers = nnx.List(layers)\n",
    "\n",
    "    def __call__(self, xt: jax.Array) -> jax.Array:\n",
    "        \"\"\"Forward pass through the PINN.\"\"\"\n",
    "        h = xt\n",
    "        for layer in self.layers[:-1]:\n",
    "            h = jnp.tanh(layer(h))\n",
    "        return self.layers[-1](h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0cf21e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print()\n",
    "print(\"Creating PINN models...\")\n",
    "\n",
    "pinn_adaptive = BurgersPINN(hidden_dims=[32, 32, 32], rngs=nnx.Rngs(SEED))\n",
    "pinn_uniform = BurgersPINN(hidden_dims=[32, 32, 32], rngs=nnx.Rngs(SEED))\n",
    "\n",
    "n_params = sum(\n",
    "    x.size for x in jax.tree_util.tree_leaves(nnx.state(pinn_adaptive, nnx.Param))\n",
    ")\n",
    "print(\"  Architecture: [2] -> [32] -> [32] -> [32] -> [1]\")\n",
    "print(f\"  Parameters: {n_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4818d572",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Step 2: Generate Initial Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a762e3",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print()\n",
    "print(\"Generating initial training data...\")\n",
    "\n",
    "key = jax.random.PRNGKey(SEED)\n",
    "NU = 0.01  # Viscosity (low = sharp gradients)\n",
    "X_MIN, X_MAX = 0.0, 2.0 * jnp.pi\n",
    "T_MAX = 0.5\n",
    "\n",
    "# Initial uniform domain points for adaptive method\n",
    "key, subkey = jax.random.split(key)\n",
    "x_domain = jax.random.uniform(subkey, (N_INITIAL_POINTS, 1), minval=X_MIN, maxval=X_MAX)\n",
    "key, subkey = jax.random.split(key)\n",
    "t_domain = jax.random.uniform(subkey, (N_INITIAL_POINTS, 1), minval=0.0, maxval=T_MAX)\n",
    "xt_adaptive = jnp.concatenate([x_domain, t_domain], axis=1)\n",
    "\n",
    "# Fixed uniform points for baseline\n",
    "key, subkey = jax.random.split(key)\n",
    "x_uniform = jax.random.uniform(\n",
    "    subkey, (N_UNIFORM_POINTS, 1), minval=X_MIN, maxval=X_MAX\n",
    ")\n",
    "key, subkey = jax.random.split(key)\n",
    "t_uniform = jax.random.uniform(subkey, (N_UNIFORM_POINTS, 1), minval=0.0, maxval=T_MAX)\n",
    "xt_uniform = jnp.concatenate([x_uniform, t_uniform], axis=1)\n",
    "\n",
    "# Initial condition points\n",
    "key, subkey = jax.random.split(key)\n",
    "x_initial = jax.random.uniform(subkey, (100, 1), minval=X_MIN, maxval=X_MAX)\n",
    "xt_initial = jnp.concatenate([x_initial, jnp.zeros((100, 1))], axis=1)\n",
    "u_initial = -jnp.sin(x_initial)\n",
    "\n",
    "# Boundary points\n",
    "key, subkey = jax.random.split(key)\n",
    "t_boundary = jax.random.uniform(subkey, (50, 1), minval=0.0, maxval=T_MAX)\n",
    "xt_left = jnp.concatenate([jnp.full((50, 1), X_MIN), t_boundary], axis=1)\n",
    "xt_right = jnp.concatenate([jnp.full((50, 1), X_MAX), t_boundary], axis=1)\n",
    "\n",
    "# Domain bounds for refinement\n",
    "bounds = jnp.array([[X_MIN, X_MAX], [0.0, T_MAX]])\n",
    "\n",
    "print(f\"  Initial adaptive points: {xt_adaptive.shape}\")\n",
    "print(f\"  Uniform baseline points: {xt_uniform.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16803b02",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Step 3: Define Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109ca22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_burgers_residual(pinn, xt, nu):\n",
    "    \"\"\"Compute Burgers equation residual: u_t + u*u_x - ν*u_xx = 0.\"\"\"\n",
    "\n",
    "    def u_scalar(xt_single):\n",
    "        return pinn(xt_single.reshape(1, 2)).squeeze()\n",
    "\n",
    "    def residual_single(xt_single):\n",
    "        # Forward pass\n",
    "        u = u_scalar(xt_single)\n",
    "\n",
    "        # First derivatives\n",
    "        du = jax.grad(u_scalar)(xt_single)\n",
    "        du_dx = du[0]\n",
    "        du_dt = du[1]\n",
    "\n",
    "        # Second derivative in x\n",
    "        def du_dx_fn(xt):\n",
    "            return jax.grad(u_scalar)(xt)[0]\n",
    "\n",
    "        d2u_dx2 = jax.grad(du_dx_fn)(xt_single)[0]\n",
    "\n",
    "        # Burgers: u_t + u*u_x - nu*u_xx = 0\n",
    "        return du_dt + u * du_dx - nu * d2u_dx2\n",
    "\n",
    "    return jax.vmap(residual_single)(xt)\n",
    "\n",
    "\n",
    "def pinn_loss(pinn, xt_domain, xt_initial, u_initial, xt_left, xt_right, nu):\n",
    "    \"\"\"Total PINN loss.\"\"\"\n",
    "    # PDE residual\n",
    "    residual = compute_burgers_residual(pinn, xt_domain, nu)\n",
    "    loss_pde = jnp.mean(residual**2)\n",
    "\n",
    "    # Initial condition\n",
    "    u_ic = pinn(xt_initial).squeeze()\n",
    "    u_target = u_initial.squeeze()\n",
    "    loss_ic = jnp.mean((u_ic - u_target) ** 2)\n",
    "\n",
    "    # Periodic-like boundary (u at left ≈ u at right)\n",
    "    u_left = pinn(xt_left).squeeze()\n",
    "    u_right = pinn(xt_right).squeeze()\n",
    "    loss_bc = jnp.mean((u_left - u_right) ** 2)\n",
    "\n",
    "    return loss_pde + 10.0 * loss_ic + loss_bc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f331e92f",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Step 4: Setup Adaptive Sampling\n",
    "\n",
    "We use RAR-D (Residual-based Adaptive Refinement with Distribution) to\n",
    "add new collocation points near high-residual regions during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e0ac41",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print()\n",
    "print(\"Setting up adaptive sampling...\")\n",
    "\n",
    "rad_config = RADConfig(beta=1.0)\n",
    "rard_config = RARDConfig(\n",
    "    num_new_points=N_REFINE_POINTS,\n",
    "    percentile_threshold=90.0,  # Focus on top 10% residual regions\n",
    "    noise_scale=0.1,\n",
    ")\n",
    "\n",
    "sampler = RADSampler(rad_config)\n",
    "refiner = RARDRefiner(rard_config)\n",
    "\n",
    "print(f\"  RAD beta: {rad_config.beta}\")\n",
    "print(f\"  Refinement points per step: {rard_config.num_new_points}\")\n",
    "print(f\"  Refinement frequency: {REFINE_FREQUENCY} steps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73533bf",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Step 5: Train with Adaptive Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef8570e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print()\n",
    "print(\"Training PINN with adaptive sampling...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "opt_adaptive = nnx.Optimizer(pinn_adaptive, optax.adam(LEARNING_RATE), wrt=nnx.Param)\n",
    "\n",
    "adaptive_history = {\n",
    "    \"step\": [],\n",
    "    \"loss\": [],\n",
    "    \"n_points\": [],\n",
    "    \"max_residual\": [],\n",
    "}\n",
    "\n",
    "# Current collocation points (will grow)\n",
    "xt_current = xt_adaptive.copy()\n",
    "\n",
    "\n",
    "def make_loss_fn(xt_domain):\n",
    "    \"\"\"Create loss function factory to avoid loop variable capture.\"\"\"\n",
    "\n",
    "    def loss_fn(model):\n",
    "        return pinn_loss(model, xt_domain, xt_initial, u_initial, xt_left, xt_right, NU)\n",
    "\n",
    "    return loss_fn\n",
    "\n",
    "\n",
    "for step in range(TRAINING_STEPS):\n",
    "    # Training step - use factory to avoid B023 loop variable capture\n",
    "    loss_fn = make_loss_fn(xt_current)\n",
    "\n",
    "    loss, grads = nnx.value_and_grad(loss_fn)(pinn_adaptive)\n",
    "    opt_adaptive.update(pinn_adaptive, grads)\n",
    "\n",
    "    # Periodic refinement\n",
    "    if step > 0 and step % REFINE_FREQUENCY == 0:\n",
    "        # Compute residuals at current points\n",
    "        residuals = compute_burgers_residual(pinn_adaptive, xt_current, NU)\n",
    "\n",
    "        # Add new points near high-residual regions\n",
    "        key, subkey = jax.random.split(key)\n",
    "        xt_current = refiner.refine(xt_current, residuals, bounds, subkey)\n",
    "\n",
    "        max_res = float(jnp.max(jnp.abs(residuals)))\n",
    "        print(\n",
    "            f\"  Step {step:4d}: loss={loss:.6e}, points={len(xt_current)}, max_res={max_res:.4e}\"\n",
    "        )\n",
    "\n",
    "    if step % 100 == 0:\n",
    "        residuals = compute_burgers_residual(pinn_adaptive, xt_current, NU)\n",
    "        adaptive_history[\"step\"].append(step)\n",
    "        adaptive_history[\"loss\"].append(float(loss))\n",
    "        adaptive_history[\"n_points\"].append(len(xt_current))\n",
    "        adaptive_history[\"max_residual\"].append(float(jnp.max(jnp.abs(residuals))))\n",
    "\n",
    "# Final\n",
    "residuals = compute_burgers_residual(pinn_adaptive, xt_current, NU)\n",
    "adaptive_history[\"step\"].append(TRAINING_STEPS)\n",
    "adaptive_history[\"loss\"].append(float(loss))\n",
    "adaptive_history[\"n_points\"].append(len(xt_current))\n",
    "adaptive_history[\"max_residual\"].append(float(jnp.max(jnp.abs(residuals))))\n",
    "\n",
    "print(f\"  Final: loss={loss:.6e}, points={len(xt_current)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5308cc92",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Step 6: Train with Uniform Sampling (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f853e2",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print()\n",
    "print(\"Training PINN with uniform sampling (baseline)...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "opt_uniform = nnx.Optimizer(pinn_uniform, optax.adam(LEARNING_RATE), wrt=nnx.Param)\n",
    "\n",
    "uniform_history = {\n",
    "    \"step\": [],\n",
    "    \"loss\": [],\n",
    "    \"max_residual\": [],\n",
    "}\n",
    "\n",
    "\n",
    "@nnx.jit\n",
    "def train_step_uniform(pinn, opt):\n",
    "    \"\"\"Single training step with uniform sampling.\"\"\"\n",
    "\n",
    "    def loss_fn(model):\n",
    "        return pinn_loss(\n",
    "            model, xt_uniform, xt_initial, u_initial, xt_left, xt_right, NU\n",
    "        )\n",
    "\n",
    "    loss, grads = nnx.value_and_grad(loss_fn)(pinn)\n",
    "    opt.update(pinn, grads)\n",
    "    return loss\n",
    "\n",
    "\n",
    "for step in range(TRAINING_STEPS):\n",
    "    loss = train_step_uniform(pinn_uniform, opt_uniform)\n",
    "\n",
    "    if step % 100 == 0:\n",
    "        residuals = compute_burgers_residual(pinn_uniform, xt_uniform, NU)\n",
    "        uniform_history[\"step\"].append(step)\n",
    "        uniform_history[\"loss\"].append(float(loss))\n",
    "        uniform_history[\"max_residual\"].append(float(jnp.max(jnp.abs(residuals))))\n",
    "\n",
    "        if step % 200 == 0:\n",
    "            print(f\"  Step {step:4d}: loss={loss:.6e}\")\n",
    "\n",
    "# Final\n",
    "residuals = compute_burgers_residual(pinn_uniform, xt_uniform, NU)\n",
    "uniform_history[\"step\"].append(TRAINING_STEPS)\n",
    "uniform_history[\"loss\"].append(float(loss))\n",
    "uniform_history[\"max_residual\"].append(float(jnp.max(jnp.abs(residuals))))\n",
    "\n",
    "print(f\"  Final: loss={loss:.6e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e05a802",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Step 7: Evaluate and Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea65bdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "print(\"Generating visualizations...\")\n",
    "\n",
    "Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "mpl.use(\"Agg\")\n",
    "\n",
    "# Evaluation grid\n",
    "x_eval = jnp.linspace(X_MIN, X_MAX, 100)\n",
    "t_eval_final = 0.3  # Evaluate at mid-time where gradients are sharp\n",
    "xt_eval = jnp.stack([x_eval, jnp.full(100, t_eval_final)], axis=1)\n",
    "\n",
    "u_adaptive = pinn_adaptive(xt_eval).squeeze()\n",
    "u_uniform = pinn_uniform(xt_eval).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e594c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 1: Training comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Loss curves\n",
    "ax1 = axes[0, 0]\n",
    "ax1.semilogy(\n",
    "    adaptive_history[\"step\"],\n",
    "    adaptive_history[\"loss\"],\n",
    "    \"b-\",\n",
    "    label=\"Adaptive\",\n",
    "    linewidth=2,\n",
    ")\n",
    "ax1.semilogy(\n",
    "    uniform_history[\"step\"],\n",
    "    uniform_history[\"loss\"],\n",
    "    \"r--\",\n",
    "    label=\"Uniform\",\n",
    "    linewidth=2,\n",
    ")\n",
    "ax1.set_xlabel(\"Training Step\", fontsize=12)\n",
    "ax1.set_ylabel(\"Loss (log scale)\", fontsize=12)\n",
    "ax1.set_title(\"Training Loss Comparison\", fontsize=14)\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Max residual\n",
    "ax2 = axes[0, 1]\n",
    "ax2.semilogy(\n",
    "    adaptive_history[\"step\"],\n",
    "    adaptive_history[\"max_residual\"],\n",
    "    \"b-\",\n",
    "    label=\"Adaptive\",\n",
    "    linewidth=2,\n",
    ")\n",
    "ax2.semilogy(\n",
    "    uniform_history[\"step\"],\n",
    "    uniform_history[\"max_residual\"],\n",
    "    \"r--\",\n",
    "    label=\"Uniform\",\n",
    "    linewidth=2,\n",
    ")\n",
    "ax2.set_xlabel(\"Training Step\", fontsize=12)\n",
    "ax2.set_ylabel(\"Max Residual (log scale)\", fontsize=12)\n",
    "ax2.set_title(\"Maximum PDE Residual\", fontsize=14)\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Point count growth\n",
    "ax3 = axes[1, 0]\n",
    "ax3.plot(\n",
    "    adaptive_history[\"step\"],\n",
    "    adaptive_history[\"n_points\"],\n",
    "    \"b-o\",\n",
    "    linewidth=2,\n",
    "    markersize=4,\n",
    ")\n",
    "ax3.axhline(\n",
    "    y=N_UNIFORM_POINTS, color=\"r\", linestyle=\"--\", label=f\"Uniform ({N_UNIFORM_POINTS})\"\n",
    ")\n",
    "ax3.set_xlabel(\"Training Step\", fontsize=12)\n",
    "ax3.set_ylabel(\"Number of Points\", fontsize=12)\n",
    "ax3.set_title(\"Collocation Point Count\", fontsize=14)\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Solution comparison\n",
    "ax4 = axes[1, 1]\n",
    "ax4.plot(np.array(x_eval), np.array(u_adaptive), \"b-\", label=\"Adaptive\", linewidth=2)\n",
    "ax4.plot(np.array(x_eval), np.array(u_uniform), \"r--\", label=\"Uniform\", linewidth=2)\n",
    "ax4.set_xlabel(\"x\", fontsize=12)\n",
    "ax4.set_ylabel(f\"u(x, t={t_eval_final})\", fontsize=12)\n",
    "ax4.set_title(\"Solution at t=0.3\", fontsize=14)\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{OUTPUT_DIR}/training_comparison.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "print(f\"  Saved: {OUTPUT_DIR}/training_comparison.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d58328e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Figure 2: Collocation point distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Final adaptive points\n",
    "ax1 = axes[0]\n",
    "ax1.scatter(\n",
    "    np.array(xt_current[:, 0]), np.array(xt_current[:, 1]), s=1, alpha=0.5, c=\"blue\"\n",
    ")\n",
    "ax1.set_xlabel(\"x\", fontsize=12)\n",
    "ax1.set_ylabel(\"t\", fontsize=12)\n",
    "ax1.set_title(f\"Adaptive Points (n={len(xt_current)})\", fontsize=14)\n",
    "ax1.set_xlim(X_MIN, X_MAX)\n",
    "ax1.set_ylim(0, T_MAX)\n",
    "\n",
    "# Uniform points\n",
    "ax2 = axes[1]\n",
    "ax2.scatter(\n",
    "    np.array(xt_uniform[:, 0]), np.array(xt_uniform[:, 1]), s=1, alpha=0.5, c=\"red\"\n",
    ")\n",
    "ax2.set_xlabel(\"x\", fontsize=12)\n",
    "ax2.set_ylabel(\"t\", fontsize=12)\n",
    "ax2.set_title(f\"Uniform Points (n={N_UNIFORM_POINTS})\", fontsize=14)\n",
    "ax2.set_xlim(X_MIN, X_MAX)\n",
    "ax2.set_ylim(0, T_MAX)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{OUTPUT_DIR}/point_distribution.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "print(f\"  Saved: {OUTPUT_DIR}/point_distribution.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6c5db7",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10a5f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "print(\"=\" * 70)\n",
    "print(\"RESULTS SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "print(\"Training Results:\")\n",
    "print(f\"  Adaptive final loss:    {adaptive_history['loss'][-1]:.6e}\")\n",
    "print(f\"  Uniform final loss:     {uniform_history['loss'][-1]:.6e}\")\n",
    "print(f\"  Adaptive final points:  {adaptive_history['n_points'][-1]}\")\n",
    "print(f\"  Uniform points:         {N_UNIFORM_POINTS}\")\n",
    "print()\n",
    "print(\"Max PDE Residual:\")\n",
    "print(f\"  Adaptive: {adaptive_history['max_residual'][-1]:.6e}\")\n",
    "print(f\"  Uniform:  {uniform_history['max_residual'][-1]:.6e}\")\n",
    "print()\n",
    "print(\"Key Insights:\")\n",
    "print(\"  1. Adaptive sampling concentrates points near high-residual regions\")\n",
    "print(\"  2. RAR-D adds points where the PDE is least satisfied\")\n",
    "print(\"  3. Better residual distribution often leads to lower overall error\")\n",
    "print(\"  4. Adaptive methods are especially useful for solutions with sharp features\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c533c1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "print(\"Adaptive sampling example completed successfully!\")\n",
    "print(f\"Results saved to: {OUTPUT_DIR}\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "py:percent,ipynb",
   "notebook_metadata_filter": "kernelspec,language_info,-jupytext.text_representation.jupytext_version,-jupytext.notebook_metadata_filter,-jupytext.cell_metadata_filter"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
