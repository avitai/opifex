{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77fca752",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# Neural Tangent Kernel (NTK) Analysis for PINNs\n",
    "\n",
    "This example demonstrates how to use the Neural Tangent Kernel to diagnose\n",
    "and understand PINN training dynamics. NTK analysis reveals spectral bias,\n",
    "predicts convergence rates, and identifies problematic modes.\n",
    "\n",
    "**Key Concepts:**\n",
    "- Empirical NTK computation for PINNs\n",
    "- Eigenvalue analysis and condition number\n",
    "- Spectral bias detection\n",
    "- Convergence rate prediction from NTK spectrum\n",
    "- Mode-wise error decay analysis\n",
    "\n",
    "**SciML Context:**\n",
    "Understanding why PINNs struggle with certain problems (high-frequency solutions,\n",
    "stiff PDEs) can be explained through NTK theory. The eigenvalue spectrum\n",
    "determines which solution modes are learned quickly vs slowly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07dd914d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "SEED = 42\n",
    "N_COLLOCATION = 100  # Points for NTK computation\n",
    "LEARNING_RATE = 1e-3\n",
    "TRAINING_STEPS = 500\n",
    "NTK_COMPUTE_FREQUENCY = 100\n",
    "\n",
    "# Output directory\n",
    "OUTPUT_DIR = \"docs/assets/examples/ntk_analysis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afbfe4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"Opifex Example: NTK Analysis for PINNs\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbafa506",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import optax\n",
    "from flax import nnx\n",
    "\n",
    "\n",
    "print(f\"JAX backend: {jax.default_backend()}\")\n",
    "print(f\"JAX devices: {jax.devices()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69082022",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from opifex.core.physics.ntk.diagnostics import (\n",
    "    detect_spectral_bias,\n",
    "    estimate_epochs_to_convergence,\n",
    "    identify_slow_modes,\n",
    ")\n",
    "from opifex.core.physics.ntk.spectral_analysis import (\n",
    "    compute_condition_number,\n",
    "    compute_effective_rank,\n",
    ")\n",
    "from opifex.core.physics.ntk.wrapper import NTKWrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb630976",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Step 1: Define a Simple PINN\n",
    "\n",
    "We use a Poisson equation PINN to demonstrate NTK analysis:\n",
    "-Δu = f(x) on [0, 1]\n",
    "u(0) = u(1) = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d080f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoissonPINN(nnx.Module):\n",
    "    \"\"\"Simple PINN for 1D Poisson equation.\"\"\"\n",
    "\n",
    "    def __init__(self, hidden_dims: list[int] | None = None, *, rngs: nnx.Rngs):\n",
    "        super().__init__()\n",
    "        if hidden_dims is None:\n",
    "            hidden_dims = [32, 32]\n",
    "        layers = []\n",
    "        in_dim = 1\n",
    "\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.append(nnx.Linear(in_dim, hidden_dim, rngs=rngs))\n",
    "            in_dim = hidden_dim\n",
    "\n",
    "        layers.append(nnx.Linear(in_dim, 1, rngs=rngs))\n",
    "        self.layers = nnx.List(layers)\n",
    "\n",
    "    def __call__(self, x: jax.Array) -> jax.Array:\n",
    "        \"\"\"Forward pass through the PINN.\"\"\"\n",
    "        h = x\n",
    "        for layer in self.layers[:-1]:\n",
    "            h = jnp.tanh(layer(h))\n",
    "        return self.layers[-1](h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31152df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "print(\"Creating PINN model...\")\n",
    "\n",
    "pinn = PoissonPINN(hidden_dims=[32, 32], rngs=nnx.Rngs(SEED))\n",
    "n_params = sum(x.size for x in jax.tree_util.tree_leaves(nnx.state(pinn, nnx.Param)))\n",
    "print(\"  Architecture: [1] -> [32] -> [32] -> [1]\")\n",
    "print(f\"  Parameters: {n_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8e695a",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Step 2: Generate Collocation Points\n",
    "\n",
    "We'll use a subset of domain points for NTK computation (full NTK is expensive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a974785d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "print(\"Generating collocation points...\")\n",
    "\n",
    "key = jax.random.PRNGKey(SEED)\n",
    "\n",
    "# Domain points for NTK computation\n",
    "x_ntk = jax.random.uniform(key, (N_COLLOCATION, 1), minval=0.0, maxval=1.0)\n",
    "\n",
    "# Training points (more for actual training)\n",
    "key, subkey = jax.random.split(key)\n",
    "x_train = jax.random.uniform(subkey, (500, 1), minval=0.0, maxval=1.0)\n",
    "\n",
    "# Boundary points\n",
    "x_bc = jnp.array([[0.0], [1.0]])\n",
    "\n",
    "print(f\"  NTK computation points: {x_ntk.shape}\")\n",
    "print(f\"  Training points: {x_train.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78ef807",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Step 3: Compute Initial NTK and Analyze Spectrum\n",
    "\n",
    "The NTK reveals the training dynamics:\n",
    "- Large eigenvalues → fast convergence for those modes\n",
    "- Small eigenvalues → slow convergence (spectral bias)\n",
    "- Condition number → overall trainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bd1f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "print(\"Computing initial NTK...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Create NTK wrapper\n",
    "ntk_wrapper = NTKWrapper(pinn)\n",
    "\n",
    "# Compute NTK matrix\n",
    "ntk_matrix = ntk_wrapper.compute_ntk(x_ntk)\n",
    "print(f\"  NTK matrix shape: {ntk_matrix.shape}\")\n",
    "\n",
    "# Compute eigenvalues (clip small negatives from numerical noise)\n",
    "eigenvalues_raw = ntk_wrapper.compute_eigenvalues(x_ntk)\n",
    "eigenvalues = jnp.maximum(eigenvalues_raw, 1e-10)  # Ensure positive for stability\n",
    "print(\n",
    "    f\"  Eigenvalues range: [{float(eigenvalues[-1]):.6e}, {float(eigenvalues[0]):.6e}]\"\n",
    ")\n",
    "\n",
    "# Compute diagnostics\n",
    "cond_number = compute_condition_number(eigenvalues)\n",
    "eff_rank = compute_effective_rank(eigenvalues)\n",
    "spectral_bias = detect_spectral_bias(eigenvalues)\n",
    "\n",
    "print()\n",
    "print(\"Initial NTK Diagnostics:\")\n",
    "print(f\"  Condition number: {float(cond_number):.2e}\")\n",
    "print(f\"  Effective rank: {float(eff_rank):.2f}\")\n",
    "print(f\"  Spectral bias indicator: {float(spectral_bias):.2f}\")\n",
    "\n",
    "# Identify slow modes\n",
    "slow_modes = identify_slow_modes(eigenvalues, LEARNING_RATE, threshold=0.999)\n",
    "n_slow = int(jnp.sum(slow_modes))\n",
    "print(f\"  Slow-converging modes: {n_slow}/{len(eigenvalues)}\")\n",
    "\n",
    "# Estimate epochs to convergence\n",
    "est_epochs = estimate_epochs_to_convergence(\n",
    "    eigenvalues, LEARNING_RATE, target_reduction=0.01\n",
    ")\n",
    "est_epochs_int = int(min(float(est_epochs), 1e9))  # Cap at 1 billion for display\n",
    "print(f\"  Estimated epochs to 99% convergence: {est_epochs_int:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73f2bf3",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Step 4: Train PINN and Track NTK Evolution\n",
    "\n",
    "We'll track how the NTK and its spectrum evolve during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f4d8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pde_residual(pinn, x):\n",
    "    \"\"\"Compute Poisson PDE residual: -d2u/dx2 - f(x) = 0.\"\"\"\n",
    "\n",
    "    def u_scalar(x_single):\n",
    "        return pinn(x_single.reshape(1, 1)).squeeze()\n",
    "\n",
    "    def residual_single(x_single):\n",
    "        # Second derivative\n",
    "        d2u_dx2 = jax.grad(jax.grad(u_scalar))(x_single)\n",
    "\n",
    "        # Source term: f(x) = pi^2 * sin(pi*x)\n",
    "        f = jnp.pi**2 * jnp.sin(jnp.pi * x_single)\n",
    "\n",
    "        return -d2u_dx2 - f\n",
    "\n",
    "    def residual_single_wrapper(x_val):\n",
    "        return residual_single(x_val.squeeze())\n",
    "\n",
    "    return jax.vmap(residual_single_wrapper)(x)\n",
    "\n",
    "\n",
    "def pinn_loss(pinn, x_domain, x_bc):\n",
    "    \"\"\"Total PINN loss.\"\"\"\n",
    "    # PDE residual\n",
    "    residual = compute_pde_residual(pinn, x_domain)\n",
    "    loss_pde = jnp.mean(residual**2)\n",
    "\n",
    "    # Boundary conditions\n",
    "    u_bc = pinn(x_bc).squeeze()\n",
    "    loss_bc = jnp.mean(u_bc**2)\n",
    "\n",
    "    return loss_pde + 10.0 * loss_bc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7619d5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "print(\"Training PINN with NTK tracking...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "opt = nnx.Optimizer(pinn, optax.adam(LEARNING_RATE), wrt=nnx.Param)\n",
    "\n",
    "losses = []\n",
    "ntk_history = {\n",
    "    \"step\": [],\n",
    "    \"condition_number\": [],\n",
    "    \"effective_rank\": [],\n",
    "    \"max_eigenvalue\": [],\n",
    "    \"min_eigenvalue\": [],\n",
    "    \"eigenvalues\": [],\n",
    "}\n",
    "\n",
    "\n",
    "@nnx.jit\n",
    "def train_step(pinn, opt, x_domain, x_bc):\n",
    "    \"\"\"Single training step for PINN.\"\"\"\n",
    "\n",
    "    def loss_fn(model):\n",
    "        return pinn_loss(model, x_domain, x_bc)\n",
    "\n",
    "    loss, grads = nnx.value_and_grad(loss_fn)(pinn)\n",
    "    opt.update(pinn, grads)\n",
    "    return loss\n",
    "\n",
    "\n",
    "for step in range(TRAINING_STEPS):\n",
    "    loss = train_step(pinn, opt, x_train, x_bc)\n",
    "    losses.append(float(loss))\n",
    "\n",
    "    # Track NTK at specified frequency\n",
    "    if step % NTK_COMPUTE_FREQUENCY == 0:\n",
    "        eigenvalues_raw = ntk_wrapper.compute_eigenvalues(x_ntk)\n",
    "        eigenvalues = jnp.maximum(eigenvalues_raw, 1e-10)  # Clip for stability\n",
    "\n",
    "        ntk_history[\"step\"].append(step)\n",
    "        ntk_history[\"condition_number\"].append(\n",
    "            float(compute_condition_number(eigenvalues))\n",
    "        )\n",
    "        ntk_history[\"effective_rank\"].append(float(compute_effective_rank(eigenvalues)))\n",
    "        ntk_history[\"max_eigenvalue\"].append(float(eigenvalues[0]))\n",
    "        ntk_history[\"min_eigenvalue\"].append(float(jnp.maximum(eigenvalues[-1], 1e-10)))\n",
    "        ntk_history[\"eigenvalues\"].append(np.array(jnp.maximum(eigenvalues, 1e-10)))\n",
    "\n",
    "        print(\n",
    "            f\"  Step {step:4d}: loss={loss:.6e}, cond={ntk_history['condition_number'][-1]:.2e}\"\n",
    "        )\n",
    "\n",
    "# Final NTK computation\n",
    "eigenvalues_final_raw = ntk_wrapper.compute_eigenvalues(x_ntk)\n",
    "eigenvalues_final = jnp.maximum(eigenvalues_final_raw, 1e-10)\n",
    "ntk_history[\"step\"].append(TRAINING_STEPS)\n",
    "ntk_history[\"condition_number\"].append(\n",
    "    float(compute_condition_number(eigenvalues_final))\n",
    ")\n",
    "ntk_history[\"effective_rank\"].append(float(compute_effective_rank(eigenvalues_final)))\n",
    "ntk_history[\"max_eigenvalue\"].append(float(eigenvalues_final[0]))\n",
    "ntk_history[\"min_eigenvalue\"].append(float(jnp.maximum(eigenvalues_final[-1], 1e-10)))\n",
    "ntk_history[\"eigenvalues\"].append(np.array(jnp.maximum(eigenvalues_final, 1e-10)))\n",
    "\n",
    "print(\n",
    "    f\"  Step {TRAINING_STEPS:4d}: loss={losses[-1]:.6e}, cond={ntk_history['condition_number'][-1]:.2e}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ef52a9",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Step 5: Evaluate Solution Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e3e1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "print(\"Evaluating trained PINN...\")\n",
    "\n",
    "# Evaluation grid\n",
    "x_eval = jnp.linspace(0, 1, 100).reshape(-1, 1)\n",
    "\n",
    "# PINN prediction\n",
    "u_pred = pinn(x_eval).squeeze()\n",
    "\n",
    "# Exact solution: u(x) = sin(pi*x) for f(x) = pi^2*sin(pi*x)\n",
    "u_exact = jnp.sin(jnp.pi * x_eval.squeeze())\n",
    "\n",
    "# L2 error\n",
    "l2_error = float(jnp.sqrt(jnp.mean((u_pred - u_exact) ** 2)))\n",
    "max_error = float(jnp.max(jnp.abs(u_pred - u_exact)))\n",
    "\n",
    "print(f\"  L2 error: {l2_error:.6e}\")\n",
    "print(f\"  Max error: {max_error:.6e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d389e54",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Step 6: Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe37b3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "print(\"Generating visualizations...\")\n",
    "\n",
    "Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "mpl.use(\"Agg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff028a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 1: NTK Eigenvalue Spectrum Evolution\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Eigenvalue spectrum at different training stages\n",
    "ax1 = axes[0, 0]\n",
    "cmap = plt.get_cmap(\"viridis\")\n",
    "colors = cmap(np.linspace(0, 1, len(ntk_history[\"eigenvalues\"])))\n",
    "for i, (step, eigs) in enumerate(\n",
    "    zip(ntk_history[\"step\"], ntk_history[\"eigenvalues\"], strict=False)\n",
    "):\n",
    "    ax1.semilogy(eigs, color=colors[i], label=f\"Step {step}\", alpha=0.8)\n",
    "ax1.set_xlabel(\"Eigenvalue Index\", fontsize=12)\n",
    "ax1.set_ylabel(\"Eigenvalue (log scale)\", fontsize=12)\n",
    "ax1.set_title(\"NTK Eigenvalue Spectrum Evolution\", fontsize=14)\n",
    "ax1.legend(fontsize=9)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Condition number over training\n",
    "ax2 = axes[0, 1]\n",
    "ax2.semilogy(\n",
    "    ntk_history[\"step\"],\n",
    "    ntk_history[\"condition_number\"],\n",
    "    \"b-o\",\n",
    "    linewidth=2,\n",
    "    markersize=6,\n",
    ")\n",
    "ax2.set_xlabel(\"Training Step\", fontsize=12)\n",
    "ax2.set_ylabel(\"Condition Number (log scale)\", fontsize=12)\n",
    "ax2.set_title(\"NTK Condition Number During Training\", fontsize=14)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Training loss\n",
    "ax3 = axes[1, 0]\n",
    "ax3.semilogy(losses, linewidth=1)\n",
    "ax3.set_xlabel(\"Training Step\", fontsize=12)\n",
    "ax3.set_ylabel(\"Loss (log scale)\", fontsize=12)\n",
    "ax3.set_title(\"Training Loss\", fontsize=14)\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Eigenvalue range\n",
    "ax4 = axes[1, 1]\n",
    "ax4.semilogy(\n",
    "    ntk_history[\"step\"],\n",
    "    ntk_history[\"max_eigenvalue\"],\n",
    "    \"b-o\",\n",
    "    label=\"Max eigenvalue\",\n",
    "    linewidth=2,\n",
    ")\n",
    "ax4.semilogy(\n",
    "    ntk_history[\"step\"],\n",
    "    ntk_history[\"min_eigenvalue\"],\n",
    "    \"r-s\",\n",
    "    label=\"Min eigenvalue\",\n",
    "    linewidth=2,\n",
    ")\n",
    "ax4.set_xlabel(\"Training Step\", fontsize=12)\n",
    "ax4.set_ylabel(\"Eigenvalue (log scale)\", fontsize=12)\n",
    "ax4.set_title(\"NTK Eigenvalue Range\", fontsize=14)\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{OUTPUT_DIR}/ntk_evolution.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "print(f\"  Saved: {OUTPUT_DIR}/ntk_evolution.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fa9055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 2: Solution and Error\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Solution comparison\n",
    "ax1 = axes[0]\n",
    "ax1.plot(np.array(x_eval), np.array(u_exact), \"b-\", label=\"Exact\", linewidth=2)\n",
    "ax1.plot(np.array(x_eval), np.array(u_pred), \"r--\", label=\"PINN\", linewidth=2)\n",
    "ax1.set_xlabel(\"x\", fontsize=12)\n",
    "ax1.set_ylabel(\"u(x)\", fontsize=12)\n",
    "ax1.set_title(\"Solution Comparison\", fontsize=14)\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Pointwise error\n",
    "ax2 = axes[1]\n",
    "error = np.abs(np.array(u_pred - u_exact))\n",
    "ax2.semilogy(np.array(x_eval), error, \"k-\", linewidth=1.5)\n",
    "ax2.set_xlabel(\"x\", fontsize=12)\n",
    "ax2.set_ylabel(\"|u_pred - u_exact| (log scale)\", fontsize=12)\n",
    "ax2.set_title(f\"Pointwise Error (L2 = {l2_error:.2e})\", fontsize=14)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{OUTPUT_DIR}/solution.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "print(f\"  Saved: {OUTPUT_DIR}/solution.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d366a2c0",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df23f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "print(\"=\" * 70)\n",
    "print(\"RESULTS SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "print(\"NTK Analysis:\")\n",
    "print(f\"  Initial condition number: {ntk_history['condition_number'][0]:.2e}\")\n",
    "print(f\"  Final condition number:   {ntk_history['condition_number'][-1]:.2e}\")\n",
    "print(f\"  Initial effective rank:   {ntk_history['effective_rank'][0]:.2f}\")\n",
    "print(f\"  Final effective rank:     {ntk_history['effective_rank'][-1]:.2f}\")\n",
    "print()\n",
    "print(\"Training Results:\")\n",
    "print(f\"  Initial loss: {losses[0]:.6e}\")\n",
    "print(f\"  Final loss:   {losses[-1]:.6e}\")\n",
    "print(f\"  L2 error:     {l2_error:.6e}\")\n",
    "print(f\"  Max error:    {max_error:.6e}\")\n",
    "print()\n",
    "print(\"Key Insights:\")\n",
    "print(\"  1. NTK condition number reflects training difficulty\")\n",
    "print(\"  2. Large eigenvalue gaps indicate spectral bias\")\n",
    "print(\"  3. Effective rank shows how many modes are actively learned\")\n",
    "print(\"  4. NTK evolves during training (finite-width effects)\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd4e900",
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "print(\"NTK analysis example completed successfully!\")\n",
    "print(f\"Results saved to: {OUTPUT_DIR}\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "py:percent,ipynb",
   "notebook_metadata_filter": "kernelspec,language_info,-jupytext.text_representation.jupytext_version,-jupytext.notebook_metadata_filter,-jupytext.cell_metadata_filter"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
