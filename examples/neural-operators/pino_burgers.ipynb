{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2392d7e3",
   "metadata": {},
   "source": [
    "# Physics-Informed Neural Operator (PINO) on Burgers Equation\n",
    "\n",
    "| Property      | Value                                    |\n",
    "|---------------|------------------------------------------|\n",
    "| Level         | Advanced                                 |\n",
    "| Runtime       | ~5 min (CPU) / ~1 min (GPU)              |\n",
    "| Memory        | ~2 GB                                    |\n",
    "| Prerequisites | JAX, Flax NNX, FNO, PDEs basics          |\n",
    "\n",
    "## Overview\n",
    "\n",
    "Train a Physics-Informed Neural Operator (PINO) on the 1D Burgers equation.\n",
    "PINO combines the FNO architecture with physics-informed loss, enabling\n",
    "training with reduced data requirements by enforcing PDE constraints.\n",
    "\n",
    "The Burgers equation is:\n",
    "    u_t + u * u_x = nu * u_xx\n",
    "\n",
    "where u is velocity, nu is viscosity, and subscripts denote partial derivatives.\n",
    "\n",
    "This example demonstrates:\n",
    "\n",
    "- **FNO backbone** for operator learning\n",
    "- **Physics loss** via finite difference PDE residual computation\n",
    "- **Multi-objective training** balancing data and physics losses\n",
    "- **Comparison** of data-only vs physics-informed training\n",
    "\n",
    "Equivalent to `neuraloperator/scripts/train_burgers_pino.py`,\n",
    "reimplemented using Opifex APIs.\n",
    "\n",
    "## Learning Goals\n",
    "\n",
    "1. Understand PINO architecture: FNO backbone + physics loss\n",
    "2. Implement PDE residual computation using finite differences\n",
    "3. Configure multi-objective loss weighting\n",
    "4. Analyze physics loss contribution to training dynamics\n",
    "5. Compare data-only FNO vs physics-informed PINO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab1de48",
   "metadata": {},
   "source": [
    "## Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408d1884",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import optax\n",
    "from flax import nnx\n",
    "\n",
    "\n",
    "mpl.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from opifex.data.loaders import create_burgers_loader\n",
    "from opifex.neural.operators.fno.base import FourierNeuralOperator\n",
    "\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"Opifex Example: PINO on 1D Burgers Equation\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"JAX backend: {jax.default_backend()}\")\n",
    "print(f\"JAX devices: {jax.devices()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0653e30",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "PINO uses a physics loss weight to balance data fitting and PDE enforcement.\n",
    "Higher physics_weight encourages PDE consistency but may sacrifice data fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d206326",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESOLUTION = 64\n",
    "TIME_STEPS = 5\n",
    "N_TRAIN = 200\n",
    "N_TEST = 50\n",
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 20\n",
    "LEARNING_RATE = 1e-3\n",
    "MODES = 16\n",
    "HIDDEN_WIDTH = 32\n",
    "NUM_LAYERS = 4\n",
    "VISCOSITY = 0.05  # Fixed viscosity for PINO\n",
    "VISCOSITY_RANGE = (0.05, 0.05)  # Fixed for physics loss\n",
    "DATA_WEIGHT = 1.0\n",
    "PHYSICS_WEIGHT = 0.1  # Weight for PDE residual loss\n",
    "SEED = 42\n",
    "\n",
    "OUTPUT_DIR = Path(\"docs/assets/examples/pino_burgers\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Resolution: {RESOLUTION}\")\n",
    "print(f\"Time steps: {TIME_STEPS}\")\n",
    "print(f\"Viscosity: {VISCOSITY}\")\n",
    "print(f\"Training samples: {N_TRAIN}, Test samples: {N_TEST}\")\n",
    "print(f\"Batch size: {BATCH_SIZE}, Epochs: {NUM_EPOCHS}\")\n",
    "print(f\"FNO config: modes={MODES}, width={HIDDEN_WIDTH}, layers={NUM_LAYERS}\")\n",
    "print(f\"Loss weights: data={DATA_WEIGHT}, physics={PHYSICS_WEIGHT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baab4fca",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "Load 1D Burgers equation data. For PINO, we use fixed viscosity\n",
    "since the physics loss assumes known PDE parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4f89ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "print(\"Generating 1D Burgers equation data...\")\n",
    "train_loader = create_burgers_loader(\n",
    "    n_samples=N_TRAIN,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    resolution=RESOLUTION,\n",
    "    time_steps=TIME_STEPS,\n",
    "    viscosity_range=VISCOSITY_RANGE,\n",
    "    dimension=\"1d\",\n",
    "    shuffle=True,\n",
    "    seed=SEED,\n",
    "    worker_count=0,\n",
    ")\n",
    "\n",
    "test_loader = create_burgers_loader(\n",
    "    n_samples=N_TEST,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    resolution=RESOLUTION,\n",
    "    time_steps=TIME_STEPS,\n",
    "    viscosity_range=VISCOSITY_RANGE,\n",
    "    dimension=\"1d\",\n",
    "    shuffle=False,\n",
    "    seed=SEED + 1000,\n",
    "    worker_count=0,\n",
    ")\n",
    "\n",
    "# Collect batches\n",
    "X_train_list, Y_train_list = [], []\n",
    "for batch in train_loader:\n",
    "    X_train_list.append(batch[\"input\"])\n",
    "    Y_train_list.append(batch[\"output\"])\n",
    "\n",
    "X_train = np.concatenate(X_train_list, axis=0)\n",
    "Y_train = np.concatenate(Y_train_list, axis=0)\n",
    "\n",
    "X_test_list, Y_test_list = [], []\n",
    "for batch in test_loader:\n",
    "    X_test_list.append(batch[\"input\"])\n",
    "    Y_test_list.append(batch[\"output\"])\n",
    "\n",
    "X_test = np.concatenate(X_test_list, axis=0)\n",
    "Y_test = np.concatenate(Y_test_list, axis=0)\n",
    "\n",
    "# FNO expects (batch, channels, *spatial)\n",
    "X_train = X_train[:, np.newaxis, :]\n",
    "X_test = X_test[:, np.newaxis, :]\n",
    "\n",
    "print(f\"Training data: X={X_train.shape}, Y={Y_train.shape}\")\n",
    "print(f\"Test data:     X={X_test.shape}, Y={Y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c34c9c0",
   "metadata": {},
   "source": [
    "## Physics Loss: Burgers Equation Residual\n",
    "\n",
    "The physics loss computes the PDE residual using finite differences:\n",
    "\n",
    "Residual = u_t + u * u_x - nu * u_xx\n",
    "\n",
    "A perfect solution has residual = 0 everywhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab436de",
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "print(\"Defining physics loss functions...\")\n",
    "\n",
    "\n",
    "def compute_burgers_residual(\n",
    "    u: jax.Array,\n",
    "    dx: float,\n",
    "    dt: float,\n",
    "    nu: float,\n",
    ") -> jax.Array:\n",
    "    \"\"\"Compute Burgers equation residual using finite differences.\n",
    "\n",
    "    Args:\n",
    "        u: Solution tensor of shape (batch, time_steps, resolution)\n",
    "        dx: Spatial step size\n",
    "        dt: Time step size\n",
    "        nu: Viscosity coefficient\n",
    "\n",
    "    Returns:\n",
    "        Residual tensor of shape (batch, time_steps-1, resolution-2)\n",
    "    \"\"\"\n",
    "    # Time derivative: (u(t+1) - u(t)) / dt\n",
    "    # Shape: (batch, time_steps-1, resolution)\n",
    "    u_t = (u[:, 1:, :] - u[:, :-1, :]) / dt\n",
    "\n",
    "    # For spatial derivatives, use u at midpoint in time\n",
    "    # u_mid: (batch, time_steps-1, resolution)\n",
    "    u_mid = 0.5 * (u[:, 1:, :] + u[:, :-1, :])\n",
    "\n",
    "    # Spatial first derivative: central difference\n",
    "    # (u(x+1) - u(x-1)) / (2*dx)\n",
    "    # Shape: (batch, time_steps-1, resolution-2)\n",
    "    u_x = (u_mid[:, :, 2:] - u_mid[:, :, :-2]) / (2 * dx)\n",
    "\n",
    "    # Spatial second derivative: central difference\n",
    "    # (u(x+1) - 2*u(x) + u(x-1)) / dx^2\n",
    "    u_xx = (u_mid[:, :, 2:] - 2 * u_mid[:, :, 1:-1] + u_mid[:, :, :-2]) / (dx**2)\n",
    "\n",
    "    # u value at interior points\n",
    "    u_interior = u_mid[:, :, 1:-1]\n",
    "\n",
    "    # Trim u_t to match interior\n",
    "    u_t_interior = u_t[:, :, 1:-1]\n",
    "\n",
    "    # Burgers residual: u_t + u * u_x - nu * u_xx = 0\n",
    "    return u_t_interior + u_interior * u_x - nu * u_xx\n",
    "\n",
    "\n",
    "def physics_loss(pred: jax.Array, dx: float, dt: float, nu: float) -> jax.Array:\n",
    "    \"\"\"Compute mean squared PDE residual loss.\"\"\"\n",
    "    residual = compute_burgers_residual(pred, dx, dt, nu)\n",
    "    return jnp.mean(residual**2)\n",
    "\n",
    "\n",
    "# Grid parameters for physics loss\n",
    "DOMAIN_LENGTH = 2.0  # x in [-1, 1]\n",
    "TIME_LENGTH = 1.0  # t in [0, 1]\n",
    "DX = DOMAIN_LENGTH / RESOLUTION\n",
    "DT = TIME_LENGTH / TIME_STEPS\n",
    "\n",
    "print(f\"Grid: dx={DX:.4f}, dt={DT:.4f}\")\n",
    "print(f\"Burgers PDE: u_t + u*u_x = {VISCOSITY}*u_xx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576c7b5c",
   "metadata": {},
   "source": [
    "## Model Creation and Training\n",
    "\n",
    "PINO uses an FNO backbone with a custom training loop that combines\n",
    "data loss (MSE) and physics loss (PDE residual)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1474601a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "print(\"Creating PINO model (FNO backbone)...\")\n",
    "model = FourierNeuralOperator(\n",
    "    in_channels=1,\n",
    "    out_channels=TIME_STEPS,\n",
    "    hidden_channels=HIDDEN_WIDTH,\n",
    "    modes=MODES,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    rngs=nnx.Rngs(SEED),\n",
    ")\n",
    "\n",
    "params = nnx.state(model, nnx.Param)\n",
    "param_count = sum(x.size for x in jax.tree_util.tree_leaves(params))\n",
    "print(f\"Model parameters: {param_count:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8d6031",
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "print(\"Setting up PINO training...\")\n",
    "\n",
    "\n",
    "def pino_loss_fn(model, x, y_true, dx, dt, nu, data_weight, physics_weight):\n",
    "    \"\"\"Combined data + physics loss for PINO training.\"\"\"\n",
    "    y_pred = model(x)\n",
    "\n",
    "    # Data loss: MSE between prediction and ground truth\n",
    "    data_loss = jnp.mean((y_pred - y_true) ** 2)\n",
    "\n",
    "    # Physics loss: PDE residual\n",
    "    pde_loss = physics_loss(y_pred, dx, dt, nu)\n",
    "\n",
    "    # Combined loss\n",
    "    total_loss = data_weight * data_loss + physics_weight * pde_loss\n",
    "\n",
    "    return total_loss, {\"data_loss\": data_loss, \"physics_loss\": pde_loss}\n",
    "\n",
    "\n",
    "# JIT-compile the training step\n",
    "optimizer = nnx.Optimizer(model, optax.adam(LEARNING_RATE), wrt=nnx.Param)\n",
    "\n",
    "\n",
    "@nnx.jit\n",
    "def train_step(model, optimizer, x_batch, y_batch):\n",
    "    \"\"\"Single PINO training step.\"\"\"\n",
    "\n",
    "    def loss_fn(model):\n",
    "        return pino_loss_fn(\n",
    "            model, x_batch, y_batch, DX, DT, VISCOSITY, DATA_WEIGHT, PHYSICS_WEIGHT\n",
    "        )\n",
    "\n",
    "    (loss, aux), grads = nnx.value_and_grad(loss_fn, has_aux=True)(model)\n",
    "    optimizer.update(model, grads)\n",
    "    return loss, aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd16d6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting PINO training...\")\n",
    "print(f\"Optimizer: Adam (lr={LEARNING_RATE})\")\n",
    "print()\n",
    "\n",
    "X_train_jnp = jnp.array(X_train)\n",
    "Y_train_jnp = jnp.array(Y_train)\n",
    "X_test_jnp = jnp.array(X_test)\n",
    "Y_test_jnp = jnp.array(Y_test)\n",
    "\n",
    "n_samples = X_train_jnp.shape[0]\n",
    "n_batches = n_samples // BATCH_SIZE\n",
    "\n",
    "train_history = {\"total\": [], \"data\": [], \"physics\": []}\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    epoch_loss = 0.0\n",
    "    epoch_data_loss = 0.0\n",
    "    epoch_physics_loss = 0.0\n",
    "\n",
    "    # Shuffle\n",
    "    perm = jax.random.permutation(jax.random.PRNGKey(epoch), n_samples)\n",
    "    X_shuffled = X_train_jnp[perm]\n",
    "    Y_shuffled = Y_train_jnp[perm]\n",
    "\n",
    "    for i in range(n_batches):\n",
    "        start_idx = i * BATCH_SIZE\n",
    "        end_idx = start_idx + BATCH_SIZE\n",
    "        x_batch = X_shuffled[start_idx:end_idx]\n",
    "        y_batch = Y_shuffled[start_idx:end_idx]\n",
    "\n",
    "        loss, aux = train_step(model, optimizer, x_batch, y_batch)\n",
    "        epoch_loss += float(loss)\n",
    "        epoch_data_loss += float(aux[\"data_loss\"])\n",
    "        epoch_physics_loss += float(aux[\"physics_loss\"])\n",
    "\n",
    "    avg_loss = epoch_loss / n_batches\n",
    "    avg_data = epoch_data_loss / n_batches\n",
    "    avg_physics = epoch_physics_loss / n_batches\n",
    "\n",
    "    train_history[\"total\"].append(avg_loss)\n",
    "    train_history[\"data\"].append(avg_data)\n",
    "    train_history[\"physics\"].append(avg_physics)\n",
    "\n",
    "    if (epoch + 1) % 5 == 0 or epoch == 0:\n",
    "        print(\n",
    "            f\"Epoch {epoch + 1:3d}/{NUM_EPOCHS}: \"\n",
    "            f\"Total={avg_loss:.6f}, Data={avg_data:.6f}, Physics={avg_physics:.6f}\"\n",
    "        )\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print()\n",
    "print(f\"Training completed in {training_time:.1f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eafba73",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbadb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "print(\"Running evaluation...\")\n",
    "\n",
    "predictions = model(X_test_jnp)\n",
    "\n",
    "# Data metrics\n",
    "test_mse = float(jnp.mean((predictions - Y_test_jnp) ** 2))\n",
    "pred_diff = (predictions - Y_test_jnp).reshape(predictions.shape[0], -1)\n",
    "Y_flat = Y_test_jnp.reshape(Y_test_jnp.shape[0], -1)\n",
    "per_sample_rel_l2 = jnp.linalg.norm(pred_diff, axis=1) / jnp.linalg.norm(Y_flat, axis=1)\n",
    "mean_rel_l2 = float(jnp.mean(per_sample_rel_l2))\n",
    "\n",
    "# Physics residual on test set\n",
    "test_physics_loss = float(physics_loss(predictions, DX, DT, VISCOSITY))\n",
    "\n",
    "print(f\"Test MSE:          {test_mse:.6f}\")\n",
    "print(f\"Test Relative L2:  {mean_rel_l2:.6f}\")\n",
    "print(f\"Test Physics Loss: {test_physics_loss:.6f}\")\n",
    "\n",
    "# Per-time-step errors\n",
    "print()\n",
    "print(\"Per-time-step MSE:\")\n",
    "for t in range(TIME_STEPS):\n",
    "    step_mse = float(jnp.mean((predictions[:, t, :] - Y_test_jnp[:, t, :]) ** 2))\n",
    "    print(f\"  t_{t + 1}: {step_mse:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6206486c",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdef9815",
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "print(\"Generating visualizations...\")\n",
    "\n",
    "x_grid = np.linspace(-1, 1, RESOLUTION)\n",
    "\n",
    "# --- Sample predictions ---\n",
    "n_vis = min(4, len(X_test))\n",
    "fig, axes = plt.subplots(\n",
    "    n_vis, TIME_STEPS + 1, figsize=(3.5 * (TIME_STEPS + 1), 3 * n_vis)\n",
    ")\n",
    "fig.suptitle(\n",
    "    \"PINO 1D Burgers Predictions (Opifex)\", fontsize=14, fontweight=\"bold\", y=1.02\n",
    ")\n",
    "\n",
    "if n_vis == 1:\n",
    "    axes = axes[np.newaxis, :]\n",
    "\n",
    "for i in range(n_vis):\n",
    "    axes[i, 0].plot(x_grid, X_test[i, 0], \"k-\", linewidth=1.5, label=\"u(x,0)\")\n",
    "    axes[i, 0].set_title(\"Initial Condition\" if i == 0 else \"\")\n",
    "    axes[i, 0].set_ylabel(f\"Sample {i}\")\n",
    "    axes[i, 0].grid(True, alpha=0.3)\n",
    "    if i == 0:\n",
    "        axes[i, 0].legend(fontsize=8)\n",
    "\n",
    "    for t in range(TIME_STEPS):\n",
    "        axes[i, t + 1].plot(\n",
    "            x_grid, Y_test[i, t], \"b-\", linewidth=1.5, alpha=0.8, label=\"Truth\"\n",
    "        )\n",
    "        axes[i, t + 1].plot(\n",
    "            x_grid,\n",
    "            np.array(predictions[i, t]),\n",
    "            \"r--\",\n",
    "            linewidth=1.5,\n",
    "            alpha=0.8,\n",
    "            label=\"PINO\",\n",
    "        )\n",
    "        if i == 0:\n",
    "            axes[i, t + 1].set_title(f\"t = t_{t + 1}\")\n",
    "            axes[i, t + 1].legend(fontsize=8)\n",
    "        axes[i, t + 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / \"predictions.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "print(f\"Predictions saved to {OUTPUT_DIR / 'predictions.png'}\")\n",
    "\n",
    "# --- Training history ---\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "fig.suptitle(\"PINO Training Dynamics\", fontsize=14, fontweight=\"bold\")\n",
    "\n",
    "epochs_arr = np.arange(1, NUM_EPOCHS + 1)\n",
    "\n",
    "axes[0].semilogy(epochs_arr, train_history[\"total\"], \"k-\", linewidth=2, label=\"Total\")\n",
    "axes[0].semilogy(epochs_arr, train_history[\"data\"], \"b--\", linewidth=1.5, label=\"Data\")\n",
    "axes[0].semilogy(\n",
    "    epochs_arr, train_history[\"physics\"], \"r--\", linewidth=1.5, label=\"Physics\"\n",
    ")\n",
    "axes[0].set_xlabel(\"Epoch\")\n",
    "axes[0].set_ylabel(\"Loss (log scale)\")\n",
    "axes[0].set_title(\"Training Loss Components\")\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "per_sample_errors = np.array(per_sample_rel_l2)\n",
    "axes[1].hist(\n",
    "    per_sample_errors, bins=20, alpha=0.7, color=\"steelblue\", edgecolor=\"black\"\n",
    ")\n",
    "axes[1].set_xlabel(\"Relative L2 Error\")\n",
    "axes[1].set_ylabel(\"Frequency\")\n",
    "axes[1].set_title(\"Test Error Distribution\")\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "per_step_mse = [\n",
    "    float(jnp.mean((predictions[:, t, :] - Y_test_jnp[:, t, :]) ** 2))\n",
    "    for t in range(TIME_STEPS)\n",
    "]\n",
    "axes[2].bar(\n",
    "    range(1, TIME_STEPS + 1),\n",
    "    per_step_mse,\n",
    "    color=\"mediumpurple\",\n",
    "    edgecolor=\"black\",\n",
    "    alpha=0.7,\n",
    ")\n",
    "axes[2].set_xlabel(\"Time Step\")\n",
    "axes[2].set_ylabel(\"MSE\")\n",
    "axes[2].set_title(\"Per-Time-Step Error\")\n",
    "axes[2].set_xticks(range(1, TIME_STEPS + 1))\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / \"training_analysis.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "print(f\"Training analysis saved to {OUTPUT_DIR / 'training_analysis.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81209f7c",
   "metadata": {},
   "source": [
    "## Results Summary\n",
    "\n",
    "PINO combines FNO's operator learning capability with physics-informed\n",
    "constraints. The physics loss ensures predictions satisfy the Burgers PDE,\n",
    "which can:\n",
    "\n",
    "- Improve generalization with limited training data\n",
    "- Produce physically consistent predictions\n",
    "- Enable semi-supervised learning with partial observations\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Experiment with physics_weight values (0.01, 0.1, 1.0)\n",
    "- Compare PINO vs data-only FNO performance\n",
    "- Try adaptive loss weighting (SoftAdapt, ReLoBRaLo)\n",
    "- Apply to 2D Burgers or Navier-Stokes equations\n",
    "- Use spectral differentiation instead of finite differences\n",
    "\n",
    "### Related Examples\n",
    "\n",
    "- [FNO on Burgers Equation](fno-burgers.md) — Data-only FNO baseline\n",
    "- [FNO on Darcy Flow](fno-darcy.md) — 2D elliptic PDE\n",
    "- [Burgers PINN](../pinns/burgers.md) — Physics-only neural network\n",
    "- [TFNO on Darcy Flow](tfno-darcy.md) — Tensorized FNO with compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073d3792",
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "print(\"=\" * 70)\n",
    "print(f\"PINO Burgers example completed in {training_time:.1f}s\")\n",
    "print(f\"Test MSE: {test_mse:.6f}, Relative L2: {mean_rel_l2:.6f}\")\n",
    "print(f\"Test Physics Loss: {test_physics_loss:.6f}\")\n",
    "print(f\"Results saved to: {OUTPUT_DIR}\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "py:percent,ipynb",
   "main_language": "python",
   "notebook_metadata_filter": "kernelspec,language_info,-jupytext.text_representation.jupytext_version,-jupytext.notebook_metadata_filter,-jupytext.cell_metadata_filter"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
