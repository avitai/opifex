{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "774519c8",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# DeepONet on Darcy Flow\n",
    "\n",
    "| Property      | Value                                    |\n",
    "|---------------|------------------------------------------|\n",
    "| Level         | Intermediate                             |\n",
    "| Runtime       | ~2 min (CPU/GPU)                         |\n",
    "| Memory        | ~1 GB                                    |\n",
    "| Prerequisites | JAX, Flax NNX, Neural Operators basics   |\n",
    "\n",
    "## Overview\n",
    "\n",
    "Train a Deep Operator Network (DeepONet) to learn the Darcy flow operator,\n",
    "which maps permeability coefficient fields to pressure solutions. Unlike FNO\n",
    "which operates on grids, DeepONet uses a branch-trunk architecture:\n",
    "\n",
    "- **Branch network**: Encodes the input function (permeability) at fixed sensors\n",
    "- **Trunk network**: Encodes evaluation locations (query coordinates)\n",
    "- **Output**: Dot product of branch and trunk embeddings\n",
    "\n",
    "This makes DeepONet resolution-independent -- once trained, it can be queried\n",
    "at arbitrary spatial locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dce6b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import optax\n",
    "from flax import nnx\n",
    "\n",
    "\n",
    "print(f\"JAX backend: {jax.default_backend()}\")\n",
    "print(f\"JAX devices: {jax.devices()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683446aa",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5de3ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data configuration\n",
    "RESOLUTION = 32\n",
    "N_TRAIN = 200\n",
    "N_TEST = 50\n",
    "N_SENSORS = RESOLUTION * RESOLUTION  # Flatten grid as sensor values\n",
    "LOCATION_DIM = 2  # (x, y) coordinates\n",
    "\n",
    "# Model configuration\n",
    "LATENT_DIM = 64\n",
    "BRANCH_HIDDEN = [256, 128]\n",
    "TRUNK_HIDDEN = [128, 128]\n",
    "\n",
    "# Training configuration\n",
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 30\n",
    "LEARNING_RATE = 1e-3\n",
    "SEED = 42\n",
    "\n",
    "ASSETS_DIR = Path(\"docs/assets/examples/deeponet_darcy\")\n",
    "ASSETS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Resolution: {RESOLUTION}x{RESOLUTION}\")\n",
    "print(f\"Training samples: {N_TRAIN}, Test samples: {N_TEST}\")\n",
    "print(f\"Sensors: {N_SENSORS}, Latent dim: {LATENT_DIM}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1b4603",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Load Darcy Flow Data\n",
    "\n",
    "We use the Grain-based Darcy loader and reshape data for DeepONet:\n",
    "- **Branch input**: Flattened permeability field `(batch, n_sensors)`\n",
    "- **Trunk input**: Grid coordinate pairs `(n_locations, 2)`\n",
    "- **Target**: Pressure values at those locations `(batch, n_locations)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef18162",
   "metadata": {},
   "outputs": [],
   "source": [
    "from opifex.data.loaders import create_darcy_loader\n",
    "\n",
    "\n",
    "# Load training data\n",
    "train_loader = create_darcy_loader(\n",
    "    n_samples=N_TRAIN,\n",
    "    batch_size=N_TRAIN,\n",
    "    resolution=RESOLUTION,\n",
    "    shuffle=True,\n",
    "    seed=SEED,\n",
    "    worker_count=0,\n",
    ")\n",
    "train_batch = next(iter(train_loader))\n",
    "X_train_grid = np.array(train_batch[\"input\"])  # (N, res, res)\n",
    "Y_train_grid = np.array(train_batch[\"output\"])  # (N, res, res)\n",
    "\n",
    "# Load test data\n",
    "test_loader = create_darcy_loader(\n",
    "    n_samples=N_TEST,\n",
    "    batch_size=N_TEST,\n",
    "    resolution=RESOLUTION,\n",
    "    shuffle=False,\n",
    "    seed=99,\n",
    "    worker_count=0,\n",
    ")\n",
    "test_batch = next(iter(test_loader))\n",
    "X_test_grid = np.array(test_batch[\"input\"])\n",
    "Y_test_grid = np.array(test_batch[\"output\"])\n",
    "\n",
    "# Flatten grids for DeepONet\n",
    "X_train_branch = X_train_grid.reshape(X_train_grid.shape[0], -1)  # (N, n_sensors)\n",
    "X_test_branch = X_test_grid.reshape(X_test_grid.shape[0], -1)\n",
    "\n",
    "# Create coordinate grid for trunk input\n",
    "x_coords = np.linspace(0, 1, RESOLUTION)\n",
    "y_coords = np.linspace(0, 1, RESOLUTION)\n",
    "xx, yy = np.meshgrid(x_coords, y_coords)\n",
    "trunk_coords = np.stack([xx.ravel(), yy.ravel()], axis=-1)  # (n_locations, 2)\n",
    "\n",
    "# Flatten target grids to match trunk locations\n",
    "Y_train_flat = Y_train_grid.reshape(Y_train_grid.shape[0], -1)  # (N, n_locations)\n",
    "Y_test_flat = Y_test_grid.reshape(Y_test_grid.shape[0], -1)\n",
    "\n",
    "print(f\"Branch input: {X_train_branch.shape}\")\n",
    "print(f\"Trunk input:  {trunk_coords.shape}\")\n",
    "print(f\"Target:       {Y_train_flat.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5e57db",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Create DeepONet Model\n",
    "\n",
    "The branch and trunk networks are MLPs with matching output dimensions.\n",
    "Their outputs are combined via dot product to produce the operator output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e010d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from opifex.neural.operators.deeponet import DeepONet\n",
    "\n",
    "\n",
    "branch_sizes = [N_SENSORS, *BRANCH_HIDDEN, LATENT_DIM]\n",
    "trunk_sizes = [LOCATION_DIM, *TRUNK_HIDDEN, LATENT_DIM]\n",
    "\n",
    "model = DeepONet(\n",
    "    branch_sizes=branch_sizes,\n",
    "    trunk_sizes=trunk_sizes,\n",
    "    activation=\"gelu\",\n",
    "    rngs=nnx.Rngs(SEED),\n",
    ")\n",
    "\n",
    "n_params = sum(x.size for x in jax.tree.leaves(nnx.state(model)))\n",
    "print(f\"Model: DeepONet (latent_dim={LATENT_DIM})\")\n",
    "print(f\"Branch: {branch_sizes}\")\n",
    "print(f\"Trunk:  {trunk_sizes}\")\n",
    "print(f\"Total parameters: {n_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d917214",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Training Loop\n",
    "\n",
    "DeepONet has a different input structure (branch + trunk) than grid-based\n",
    "operators, so we use a custom training loop with optax directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fda7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = nnx.Optimizer(model, optax.adam(LEARNING_RATE), wrt=nnx.Param)\n",
    "print(f\"Optimizer: Adam (lr={LEARNING_RATE})\")\n",
    "\n",
    "# Convert trunk to JAX array (shared across all samples)\n",
    "trunk_jax = jnp.array(trunk_coords)\n",
    "\n",
    "# Convert data to JAX arrays\n",
    "X_train_jax = jnp.array(X_train_branch)\n",
    "Y_train_jax = jnp.array(Y_train_flat)\n",
    "\n",
    "\n",
    "@nnx.jit\n",
    "def train_step(model, opt, x_branch, y_target):\n",
    "    \"\"\"Single training step for DeepONet.\"\"\"\n",
    "\n",
    "    def loss_fn(model):\n",
    "        # Expand trunk for batch: (n_locations, 2) -> (batch, n_locations, 2)\n",
    "        batch_size = x_branch.shape[0]\n",
    "        trunk_batch = jnp.broadcast_to(trunk_jax[None], (batch_size, *trunk_jax.shape))\n",
    "        y_pred = model(x_branch, trunk_batch)  # (batch, n_locations)\n",
    "        return jnp.mean((y_pred - y_target) ** 2)\n",
    "\n",
    "    loss, grads = nnx.value_and_grad(loss_fn)(model)\n",
    "    opt.update(model, grads)\n",
    "    return loss\n",
    "\n",
    "\n",
    "print(f\"\\nStarting training ({NUM_EPOCHS} epochs)...\")\n",
    "import time\n",
    "\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "key = jax.random.PRNGKey(SEED)\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # Shuffle training data\n",
    "    key, subkey = jax.random.split(key)\n",
    "    perm = jax.random.permutation(subkey, X_train_jax.shape[0])\n",
    "    X_shuffled = X_train_jax[perm]\n",
    "    Y_shuffled = Y_train_jax[perm]\n",
    "\n",
    "    # Mini-batch training\n",
    "    epoch_losses = []\n",
    "    n_batches = X_train_jax.shape[0] // BATCH_SIZE\n",
    "    for i in range(n_batches):\n",
    "        start = i * BATCH_SIZE\n",
    "        end = start + BATCH_SIZE\n",
    "        loss = train_step(model, opt, X_shuffled[start:end], Y_shuffled[start:end])\n",
    "        epoch_losses.append(float(loss))\n",
    "\n",
    "    train_loss = np.mean(epoch_losses)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    # Validation loss on test set\n",
    "    X_test_jax = jnp.array(X_test_branch)\n",
    "    Y_test_jax = jnp.array(Y_test_flat)\n",
    "    trunk_test = jnp.broadcast_to(\n",
    "        trunk_jax[None], (X_test_jax.shape[0], *trunk_jax.shape)\n",
    "    )\n",
    "    test_pred = model(X_test_jax, trunk_test)\n",
    "    val_loss = float(jnp.mean((test_pred - Y_test_jax) ** 2))\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "    if (epoch + 1) % 10 == 0 or epoch == 0:\n",
    "        print(\n",
    "            f\"  Epoch {epoch + 1:3d}/{NUM_EPOCHS}: train_loss={train_loss:.6f}, val_loss={val_loss:.6f}\"\n",
    "        )\n",
    "\n",
    "elapsed = time.time() - t0\n",
    "print(f\"\\nTraining completed in {elapsed:.1f}s\")\n",
    "print(f\"Final train loss: {train_losses[-1]:.6e}\")\n",
    "print(f\"Final val loss:   {val_losses[-1]:.6e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc973c2",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b172532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full test evaluation\n",
    "X_test_jax = jnp.array(X_test_branch)\n",
    "Y_test_jax = jnp.array(Y_test_flat)\n",
    "trunk_test = jnp.broadcast_to(trunk_jax[None], (X_test_jax.shape[0], *trunk_jax.shape))\n",
    "predictions = model(X_test_jax, trunk_test)\n",
    "\n",
    "test_mse = float(jnp.mean((predictions - Y_test_jax) ** 2))\n",
    "\n",
    "# Per-sample relative L2 error\n",
    "per_sample_l2 = jnp.sqrt(jnp.sum((predictions - Y_test_jax) ** 2, axis=-1))\n",
    "per_sample_norm = jnp.sqrt(jnp.sum(Y_test_jax**2, axis=-1))\n",
    "relative_l2 = per_sample_l2 / (per_sample_norm + 1e-8)\n",
    "mean_rel_l2 = float(jnp.mean(relative_l2))\n",
    "\n",
    "print(f\"\\nTest MSE:         {test_mse:.6f}\")\n",
    "print(f\"Test Relative L2: {mean_rel_l2:.6f}\")\n",
    "print(f\"Min Relative L2:  {float(jnp.min(relative_l2)):.6f}\")\n",
    "print(f\"Max Relative L2:  {float(jnp.max(relative_l2)):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70dc20da",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Visualizations\n",
    "\n",
    "### Sample Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e570d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "\n",
    "mpl.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Reshape predictions back to grid\n",
    "pred_grid = np.array(predictions).reshape(-1, RESOLUTION, RESOLUTION)\n",
    "truth_grid = Y_test_grid\n",
    "\n",
    "fig, axes = plt.subplots(3, 4, figsize=(16, 12))\n",
    "for row in range(3):\n",
    "    idx = row\n",
    "    vmin = float(truth_grid[idx].min())\n",
    "    vmax = float(truth_grid[idx].max())\n",
    "\n",
    "    axes[row, 0].imshow(X_test_grid[idx], cmap=\"viridis\")\n",
    "    axes[row, 0].set_title(\"Input (Permeability)\" if row == 0 else \"\")\n",
    "    axes[row, 0].axis(\"off\")\n",
    "\n",
    "    axes[row, 1].imshow(truth_grid[idx], cmap=\"RdBu_r\", vmin=vmin, vmax=vmax)\n",
    "    axes[row, 1].set_title(\"Ground Truth\" if row == 0 else \"\")\n",
    "    axes[row, 1].axis(\"off\")\n",
    "\n",
    "    axes[row, 2].imshow(pred_grid[idx], cmap=\"RdBu_r\", vmin=vmin, vmax=vmax)\n",
    "    axes[row, 2].set_title(\"DeepONet Prediction\" if row == 0 else \"\")\n",
    "    axes[row, 2].axis(\"off\")\n",
    "\n",
    "    err = np.abs(truth_grid[idx] - pred_grid[idx])\n",
    "    im = axes[row, 3].imshow(err, cmap=\"hot\")\n",
    "    axes[row, 3].set_title(\"Absolute Error\" if row == 0 else \"\")\n",
    "    axes[row, 3].axis(\"off\")\n",
    "    fig.colorbar(im, ax=axes[row, 3], shrink=0.8)\n",
    "\n",
    "plt.suptitle(\"DeepONet on Darcy Flow: Sample Predictions\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig(ASSETS_DIR / \"predictions.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "print(f\"Predictions saved to {ASSETS_DIR / 'predictions.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7210e724",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "### Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff06a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4.5))\n",
    "\n",
    "# Relative L2 error distribution\n",
    "axes[0].hist(np.array(relative_l2), bins=20, color=\"steelblue\", edgecolor=\"white\")\n",
    "axes[0].set_xlabel(\"Relative L2 Error\")\n",
    "axes[0].set_ylabel(\"Count\")\n",
    "axes[0].set_title(\"Error Distribution\")\n",
    "axes[0].axvline(\n",
    "    mean_rel_l2, color=\"red\", linestyle=\"--\", label=f\"Mean: {mean_rel_l2:.4f}\"\n",
    ")\n",
    "axes[0].legend()\n",
    "\n",
    "# Training and validation loss curves\n",
    "axes[1].semilogy(\n",
    "    range(1, NUM_EPOCHS + 1), train_losses, label=\"Train Loss\", color=\"steelblue\"\n",
    ")\n",
    "axes[1].semilogy(range(1, NUM_EPOCHS + 1), val_losses, label=\"Val Loss\", color=\"coral\")\n",
    "axes[1].set_xlabel(\"Epoch\")\n",
    "axes[1].set_ylabel(\"MSE Loss\")\n",
    "axes[1].set_title(\"Training Progress\")\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle(\"DeepONet Error Analysis\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig(ASSETS_DIR / \"error_analysis.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "print(f\"Error analysis saved to {ASSETS_DIR / 'error_analysis.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fedcb35",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "### Branch-Trunk Embedding Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959b73e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze learned embeddings\n",
    "branch_out = model.get_branch_output(X_test_jax[:5])\n",
    "trunk_out = model.get_trunk_output(trunk_jax)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4.5))\n",
    "\n",
    "# Branch embedding similarity\n",
    "branch_np = np.array(branch_out)\n",
    "similarity = branch_np @ branch_np.T\n",
    "similarity /= np.max(np.abs(similarity))\n",
    "im0 = axes[0].imshow(similarity, cmap=\"coolwarm\", vmin=-1, vmax=1)\n",
    "axes[0].set_title(\"Branch Embedding Similarity (5 samples)\")\n",
    "axes[0].set_xlabel(\"Sample\")\n",
    "axes[0].set_ylabel(\"Sample\")\n",
    "fig.colorbar(im0, ax=axes[0], shrink=0.8)\n",
    "\n",
    "# Trunk embedding: first 3 principal components as RGB\n",
    "trunk_np = np.array(trunk_out)  # (n_locations, latent_dim)\n",
    "# Use first 3 dims as RGB channels\n",
    "trunk_rgb = trunk_np[:, :3]\n",
    "trunk_rgb = (trunk_rgb - trunk_rgb.min(axis=0)) / (\n",
    "    trunk_rgb.max(axis=0) - trunk_rgb.min(axis=0) + 1e-8\n",
    ")\n",
    "trunk_img = trunk_rgb.reshape(RESOLUTION, RESOLUTION, 3)\n",
    "axes[1].imshow(trunk_img)\n",
    "axes[1].set_title(\"Trunk Embedding (first 3 dims as RGB)\")\n",
    "axes[1].axis(\"off\")\n",
    "\n",
    "plt.suptitle(\"DeepONet Learned Representations\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig(ASSETS_DIR / \"branch_trunk.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "print(f\"Branch-trunk analysis saved to {ASSETS_DIR / 'branch_trunk.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3d4ecb",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dea312",
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "print(\"=\" * 70)\n",
    "print(f\"DeepONet Darcy Flow example completed in {elapsed:.1f}s\")\n",
    "print(f\"Test MSE: {test_mse:.6f}, Relative L2: {mean_rel_l2:.6f}\")\n",
    "print(f\"Results saved to: {ASSETS_DIR}\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "py:percent,ipynb",
   "main_language": "python",
   "notebook_metadata_filter": "kernelspec,language_info,-jupytext.text_representation.jupytext_version,-jupytext.notebook_metadata_filter,-jupytext.cell_metadata_filter"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
