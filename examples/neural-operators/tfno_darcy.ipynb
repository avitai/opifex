{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "609ab44c",
   "metadata": {},
   "source": [
    "# TFNO on Darcy Flow\n",
    "\n",
    "| Property      | Value                                    |\n",
    "|---------------|------------------------------------------|\n",
    "| Level         | Intermediate                             |\n",
    "| Runtime       | ~3 min (CPU), ~30s (GPU)                 |\n",
    "| Memory        | ~1 GB                                    |\n",
    "| Prerequisites | JAX, Flax NNX, Neural Operators basics   |\n",
    "\n",
    "## Overview\n",
    "\n",
    "Train a Tensorized Fourier Neural Operator (TFNO) on the Darcy flow problem.\n",
    "TFNO extends the FNO architecture with complex-valued spectral convolution\n",
    "weights that operate directly on Fourier coefficients.\n",
    "\n",
    "This example demonstrates:\n",
    "\n",
    "- **Complex spectral weights** for enhanced frequency-domain learning\n",
    "- **create_tucker_fno()** factory for simplified model creation\n",
    "- **Mode truncation** for efficient spectral convolutions\n",
    "- **Comparison** with standard FNO architecture\n",
    "\n",
    "Equivalent to `neuraloperator` Tucker FNO examples,\n",
    "reimplemented using Opifex APIs.\n",
    "\n",
    "## Learning Goals\n",
    "\n",
    "1. Use `create_tucker_fno()` factory for parameter-efficient FNO\n",
    "2. Understand Tucker decomposition compression in spectral layers\n",
    "3. Compare TFNO vs FNO parameter counts and accuracy tradeoffs\n",
    "4. Analyze compression statistics per layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a78244b",
   "metadata": {},
   "source": [
    "## Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0a9630",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "from flax import nnx\n",
    "\n",
    "\n",
    "mpl.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from opifex.core.training import Trainer, TrainingConfig\n",
    "from opifex.data.loaders import create_darcy_loader\n",
    "from opifex.neural.operators.fno.base import FourierNeuralOperator\n",
    "from opifex.neural.operators.fno.tensorized import create_tucker_fno\n",
    "\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"Opifex Example: TFNO (Tucker-Factorized FNO) on Darcy Flow\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"JAX backend: {jax.default_backend()}\")\n",
    "print(f\"JAX devices: {jax.devices()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a227678",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "The rank parameter controls compression: rank=0.1 means ~10% of parameters\n",
    "compared to equivalent non-factorized weight tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f92f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESOLUTION = 64\n",
    "N_TRAIN = 200\n",
    "N_TEST = 50\n",
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 15\n",
    "LEARNING_RATE = 1e-3\n",
    "MODES = (12, 12)\n",
    "HIDDEN_WIDTH = 32\n",
    "NUM_LAYERS = 4\n",
    "RANK = 0.1  # Tucker compression ratio (10% of full parameters)\n",
    "SEED = 42\n",
    "\n",
    "OUTPUT_DIR = Path(\"docs/assets/examples/tfno_darcy\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Resolution: {RESOLUTION}x{RESOLUTION}\")\n",
    "print(f\"Training samples: {N_TRAIN}, Test samples: {N_TEST}\")\n",
    "print(f\"Batch size: {BATCH_SIZE}, Epochs: {NUM_EPOCHS}\")\n",
    "print(f\"FNO config: modes={MODES}, width={HIDDEN_WIDTH}, layers={NUM_LAYERS}\")\n",
    "print(f\"Tucker rank: {RANK} (target ~{int(RANK * 100)}% compression)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2b0384",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "Use the standard Darcy flow loader - data format is identical for FNO and TFNO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d449722",
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "print(\"Generating Darcy flow data...\")\n",
    "train_loader = create_darcy_loader(\n",
    "    n_samples=N_TRAIN,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    resolution=RESOLUTION,\n",
    "    shuffle=True,\n",
    "    seed=SEED,\n",
    "    worker_count=0,\n",
    ")\n",
    "\n",
    "test_loader = create_darcy_loader(\n",
    "    n_samples=N_TEST,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    resolution=RESOLUTION,\n",
    "    shuffle=False,\n",
    "    seed=SEED + 1000,\n",
    "    worker_count=0,\n",
    ")\n",
    "\n",
    "# Collect batches into arrays\n",
    "X_train_list, Y_train_list = [], []\n",
    "for batch in train_loader:\n",
    "    X_train_list.append(batch[\"input\"])\n",
    "    Y_train_list.append(batch[\"output\"])\n",
    "\n",
    "X_train = np.concatenate(X_train_list, axis=0)\n",
    "Y_train = np.concatenate(Y_train_list, axis=0)\n",
    "\n",
    "X_test_list, Y_test_list = [], []\n",
    "for batch in test_loader:\n",
    "    X_test_list.append(batch[\"input\"])\n",
    "    Y_test_list.append(batch[\"output\"])\n",
    "\n",
    "X_test = np.concatenate(X_test_list, axis=0)\n",
    "Y_test = np.concatenate(Y_test_list, axis=0)\n",
    "\n",
    "# Add channel dimension for TFNO (expects batch, channels, H, W)\n",
    "X_train = X_train[:, np.newaxis, :, :]\n",
    "Y_train = Y_train[:, np.newaxis, :, :]\n",
    "X_test = X_test[:, np.newaxis, :, :]\n",
    "Y_test = Y_test[:, np.newaxis, :, :]\n",
    "\n",
    "print(f\"Training data: X={X_train.shape}, Y={Y_train.shape}\")\n",
    "print(f\"Test data:     X={X_test.shape}, Y={Y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e134d6e2",
   "metadata": {},
   "source": [
    "## Model Creation and Comparison\n",
    "\n",
    "Create both TFNO and standard FNO to compare parameter counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ae0484",
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "print(\"Creating TFNO model (Tucker-factorized)...\")\n",
    "tfno_model = create_tucker_fno(\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    hidden_channels=HIDDEN_WIDTH,\n",
    "    modes=MODES,\n",
    "    rank=RANK,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    rngs=nnx.Rngs(SEED),\n",
    ")\n",
    "\n",
    "# Count TFNO parameters\n",
    "tfno_params = nnx.state(tfno_model, nnx.Param)\n",
    "tfno_param_count = sum(x.size for x in jax.tree_util.tree_leaves(tfno_params))\n",
    "\n",
    "# Create equivalent standard FNO for comparison\n",
    "print(\"Creating standard FNO for comparison...\")\n",
    "fno_model = FourierNeuralOperator(\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    hidden_channels=HIDDEN_WIDTH,\n",
    "    modes=max(MODES),  # FNO takes single mode value\n",
    "    num_layers=NUM_LAYERS,\n",
    "    rngs=nnx.Rngs(SEED + 1),\n",
    ")\n",
    "\n",
    "fno_params = nnx.state(fno_model, nnx.Param)\n",
    "fno_param_count = sum(x.size for x in jax.tree_util.tree_leaves(fno_params))\n",
    "\n",
    "print()\n",
    "print(\"Model: Tucker-Factorized FNO (TFNO)\")\n",
    "print(f\"  Modes: {MODES}, Hidden width: {HIDDEN_WIDTH}, Layers: {NUM_LAYERS}\")\n",
    "print(f\"  Tucker rank: {RANK}\")\n",
    "print(f\"  TFNO parameters: {tfno_param_count:,}\")\n",
    "print(f\"  Standard FNO parameters: {fno_param_count:,}\")\n",
    "print(f\"  Parameter reduction: {(1 - tfno_param_count / fno_param_count) * 100:.1f}%\")\n",
    "\n",
    "# Get compression stats from first layer\n",
    "layer_stats = tfno_model.tfno_layers[0].get_compression_stats()\n",
    "print()\n",
    "print(\"Per-layer compression stats:\")\n",
    "print(f\"  Factorized params: {layer_stats['factorized_parameters']:,}\")\n",
    "print(f\"  Dense equivalent:  {layer_stats['equivalent_dense_parameters']:,}\")\n",
    "print(f\"  Compression ratio: {layer_stats['compression_ratio']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b69c2a",
   "metadata": {},
   "source": [
    "## Training with Opifex Trainer\n",
    "\n",
    "TFNO uses the same `Trainer.fit()` interface as standard FNO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fcf2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "print(\"Setting up Trainer...\")\n",
    "config = TrainingConfig(\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=tfno_model,\n",
    "    config=config,\n",
    "    rngs=nnx.Rngs(SEED),\n",
    ")\n",
    "\n",
    "print(f\"Optimizer: Adam (lr={LEARNING_RATE})\")\n",
    "print()\n",
    "print(\"Starting training...\")\n",
    "start_time = time.time()\n",
    "\n",
    "trained_model, metrics = trainer.fit(\n",
    "    train_data=(jnp.array(X_train), jnp.array(Y_train)),\n",
    "    val_data=(jnp.array(X_test), jnp.array(Y_test)),\n",
    ")\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(f\"Training completed in {training_time:.1f}s\")\n",
    "print(f\"Final train loss: {metrics.get('final_train_loss', 'N/A')}\")\n",
    "print(f\"Final val loss:   {metrics.get('final_val_loss', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137ce449",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad037f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "print(\"Running evaluation...\")\n",
    "X_test_jnp = jnp.array(X_test)\n",
    "Y_test_jnp = jnp.array(Y_test)\n",
    "\n",
    "predictions = trained_model(X_test_jnp)\n",
    "\n",
    "# Overall metrics\n",
    "test_mse = float(jnp.mean((predictions - Y_test_jnp) ** 2))\n",
    "\n",
    "pred_diff = (predictions - Y_test_jnp).reshape(predictions.shape[0], -1)\n",
    "Y_flat = Y_test_jnp.reshape(Y_test_jnp.shape[0], -1)\n",
    "per_sample_rel_l2 = jnp.linalg.norm(pred_diff, axis=1) / jnp.linalg.norm(Y_flat, axis=1)\n",
    "mean_rel_l2 = float(jnp.mean(per_sample_rel_l2))\n",
    "\n",
    "print(f\"Test MSE:         {test_mse:.6f}\")\n",
    "print(f\"Test Relative L2: {mean_rel_l2:.6f}\")\n",
    "print(f\"Min Relative L2:  {float(jnp.min(per_sample_rel_l2)):.6f}\")\n",
    "print(f\"Max Relative L2:  {float(jnp.max(per_sample_rel_l2)):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2d120b",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375a20f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "print(\"Generating visualizations...\")\n",
    "\n",
    "# --- Sample predictions ---\n",
    "n_vis = min(4, len(X_test))\n",
    "fig, axes = plt.subplots(n_vis, 4, figsize=(16, 4 * n_vis))\n",
    "fig.suptitle(\"TFNO Darcy Flow Predictions (Opifex)\", fontsize=14, fontweight=\"bold\")\n",
    "\n",
    "for i in range(n_vis):\n",
    "    axes[i, 0].imshow(X_test[i, 0], cmap=\"viridis\")\n",
    "    axes[i, 0].set_title(\"Input (Permeability)\" if i == 0 else \"\")\n",
    "    axes[i, 0].set_ylabel(f\"Sample {i}\")\n",
    "    axes[i, 0].axis(\"off\")\n",
    "\n",
    "    axes[i, 1].imshow(Y_test[i, 0], cmap=\"RdBu_r\")\n",
    "    axes[i, 1].set_title(\"Ground Truth\" if i == 0 else \"\")\n",
    "    axes[i, 1].axis(\"off\")\n",
    "\n",
    "    pred_np = np.array(predictions[i, 0])\n",
    "    axes[i, 2].imshow(pred_np, cmap=\"RdBu_r\")\n",
    "    axes[i, 2].set_title(\"TFNO Prediction\" if i == 0 else \"\")\n",
    "    axes[i, 2].axis(\"off\")\n",
    "\n",
    "    error = np.abs(pred_np - Y_test[i, 0])\n",
    "    im = axes[i, 3].imshow(error, cmap=\"Reds\")\n",
    "    axes[i, 3].set_title(\"Absolute Error\" if i == 0 else \"\")\n",
    "    axes[i, 3].axis(\"off\")\n",
    "    plt.colorbar(im, ax=axes[i, 3], fraction=0.046, pad=0.04)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / \"predictions.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "print(f\"Sample predictions saved to {OUTPUT_DIR / 'predictions.png'}\")\n",
    "\n",
    "# --- Error and compression analysis ---\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "fig.suptitle(\"TFNO Analysis\", fontsize=14, fontweight=\"bold\")\n",
    "\n",
    "# Error distribution\n",
    "per_sample_errors = np.array(per_sample_rel_l2)\n",
    "axes[0].hist(\n",
    "    per_sample_errors, bins=20, alpha=0.7, color=\"steelblue\", edgecolor=\"black\"\n",
    ")\n",
    "axes[0].set_xlabel(\"Relative L2 Error\")\n",
    "axes[0].set_ylabel(\"Frequency\")\n",
    "axes[0].set_title(\"Error Distribution\")\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Parameter comparison\n",
    "models = [\"Standard\\nFNO\", \"Tucker\\nTFNO\"]\n",
    "params = [fno_param_count, tfno_param_count]\n",
    "colors = [\"coral\", \"steelblue\"]\n",
    "bars = axes[1].bar(models, params, color=colors, edgecolor=\"black\", alpha=0.7)\n",
    "axes[1].set_ylabel(\"Number of Parameters\")\n",
    "axes[1].set_title(\"Parameter Comparison\")\n",
    "for bar, count in zip(bars, params, strict=False):\n",
    "    axes[1].text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        bar.get_height(),\n",
    "        f\"{count:,}\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontsize=10,\n",
    "    )\n",
    "axes[1].grid(True, alpha=0.3, axis=\"y\")\n",
    "\n",
    "# Per-sample error\n",
    "axes[2].plot(per_sample_errors, \"o-\", alpha=0.7, color=\"coral\", markersize=3)\n",
    "axes[2].set_xlabel(\"Sample Index\")\n",
    "axes[2].set_ylabel(\"Relative L2 Error\")\n",
    "axes[2].set_title(\"Error per Sample\")\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / \"analysis.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "print(f\"Analysis saved to {OUTPUT_DIR / 'analysis.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a79f3ac",
   "metadata": {},
   "source": [
    "## Results Summary\n",
    "\n",
    "TFNO achieves similar accuracy to FNO with significantly fewer parameters.\n",
    "The Tucker decomposition compresses spectral convolution weights while\n",
    "preserving the essential frequency components.\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Try different rank values (0.05, 0.2) to explore accuracy-compression tradeoffs\n",
    "- Compare with CP (`create_cp_fno()`) and Tensor Train (`create_tt_fno()`) factorizations\n",
    "- Apply TFNO to larger problems where memory savings are more significant\n",
    "- Experiment with progressive rank training (start low, increase during training)\n",
    "\n",
    "### Related Examples\n",
    "\n",
    "- [FNO on Darcy Flow](fno-darcy.md) — Standard FNO baseline\n",
    "- [FNO on Burgers Equation](fno-burgers.md) — 1D temporal evolution\n",
    "- [Operator Comparison Tour](operator-tour.md) — Compare all operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c0b634",
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "print(\"=\" * 70)\n",
    "print(f\"TFNO Darcy example completed in {training_time:.1f}s\")\n",
    "print(f\"Test MSE: {test_mse:.6f}, Relative L2: {mean_rel_l2:.6f}\")\n",
    "print(f\"Parameters: TFNO={tfno_param_count:,} vs FNO={fno_param_count:,}\")\n",
    "print(f\"Results saved to: {OUTPUT_DIR}\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "py:percent,ipynb",
   "main_language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
