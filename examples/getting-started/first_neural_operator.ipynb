{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ab0a404",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# Your First Neural Operator: Zero-Shot Super-Resolution\n",
    "\n",
    "| Property      | Value                                |\n",
    "|---------------|--------------------------------------|\n",
    "| Level         | Beginner                             |\n",
    "| Runtime       | ~2 minutes                           |\n",
    "| Memory        | ~1 GB                                |\n",
    "| Prerequisites | `source activate.sh`                 |\n",
    "\n",
    "## Overview\n",
    "\n",
    "Train a Fourier Neural Operator (FNO) on the Darcy flow equation and demonstrate its\n",
    "**killer feature: zero-shot super-resolution**.\n",
    "\n",
    "The FNO learns an operator that maps permeability fields to pressure solutions.\n",
    "Once trained at 32x32 resolution, it can make predictions at 64x64 WITHOUT retraining!\n",
    "\n",
    "**This is THE key differentiator of neural operators vs standard neural networks.**\n",
    "\n",
    "We'll achieve:\n",
    "- ~15-20% relative L2 error at training resolution (32x32)\n",
    "- The model learns to map permeability to pressure solutions\n",
    "\n",
    "**Note**: State-of-the-art results (~2% error) require H1 loss and LR scheduling.\n",
    "This example focuses on demonstrating the Opifex APIs with minimal configuration.\n",
    "\n",
    "This example uses Opifex APIs:\n",
    "- `create_darcy_loader` for data generation\n",
    "- `FourierNeuralOperator` for the model\n",
    "- `Trainer.fit()` for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0409b66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "from flax import nnx\n",
    "\n",
    "\n",
    "mpl.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from opifex.core.training import Trainer, TrainingConfig\n",
    "from opifex.data.loaders import create_darcy_loader\n",
    "from opifex.neural.operators.common.embeddings import GridEmbedding2D\n",
    "from opifex.neural.operators.fno.base import FourierNeuralOperator\n",
    "\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"Your First Neural Operator: Zero-Shot Super-Resolution\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"JAX backend: {jax.default_backend()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a6b7cc",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## The Darcy Flow Equation\n",
    "\n",
    "Darcy flow describes fluid flow through porous media:\n",
    "\n",
    "    ∇·(a(x)∇u(x)) = f(x)\n",
    "\n",
    "where:\n",
    "- a(x) is the permeability coefficient field (input)\n",
    "- u(x) is the pressure solution (output)\n",
    "\n",
    "We train an FNO to learn the operator: a(x) → u(x)\n",
    "\n",
    "This is a standard benchmark for neural operators, used by\n",
    "NeuralOperator, DeepXDE, and PhysicsNeMo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9a732f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration - based on NeuralOperator reference implementation\n",
    "TRAIN_RESOLUTION = 32  # Train at this resolution\n",
    "TEST_RESOLUTION_1 = 32  # Same as training\n",
    "TEST_RESOLUTION_2 = 64  # 2x higher - zero-shot!\n",
    "\n",
    "N_TRAIN = 1000  # More training data for better generalization\n",
    "N_TEST = 100\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 200  # Epochs for training\n",
    "LEARNING_RATE = 1e-2  # Higher LR for faster convergence\n",
    "MODES = 12  # Fourier modes (should be less than resolution/2)\n",
    "HIDDEN_CHANNELS = 32\n",
    "NUM_LAYERS = 4\n",
    "SEED = 42\n",
    "\n",
    "OUTPUT_DIR = Path(\"docs/assets/examples/first_neural_operator\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print()\n",
    "print(f\"Training resolution: {TRAIN_RESOLUTION}x{TRAIN_RESOLUTION}\")\n",
    "print(\n",
    "    f\"Test resolutions: {TEST_RESOLUTION_1}x{TEST_RESOLUTION_1}, \"\n",
    "    f\"{TEST_RESOLUTION_2}x{TEST_RESOLUTION_2} (zero-shot)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c22fb17",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Data Loading with Opifex\n",
    "\n",
    "Opifex provides `create_darcy_loader()` which generates Darcy flow solutions\n",
    "on-demand using a spectral solver. The loader uses Google Grain for efficient\n",
    "streaming and batching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b672ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "print(\"Loading Darcy flow data...\")\n",
    "\n",
    "# Training data at low resolution\n",
    "# Disable normalization for cross-resolution testing\n",
    "train_loader = create_darcy_loader(\n",
    "    n_samples=N_TRAIN,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    resolution=TRAIN_RESOLUTION,\n",
    "    shuffle=True,\n",
    "    seed=SEED,\n",
    "    worker_count=0,\n",
    "    enable_normalization=False,\n",
    ")\n",
    "\n",
    "# Test data at SAME resolution\n",
    "test_loader_32 = create_darcy_loader(\n",
    "    n_samples=N_TEST,\n",
    "    batch_size=N_TEST,  # All at once for evaluation\n",
    "    resolution=TEST_RESOLUTION_1,\n",
    "    shuffle=False,\n",
    "    seed=SEED + 1000,\n",
    "    worker_count=0,\n",
    "    enable_normalization=False,\n",
    ")\n",
    "\n",
    "# Test data at HIGHER resolution - for zero-shot super-resolution!\n",
    "test_loader_64 = create_darcy_loader(\n",
    "    n_samples=N_TEST,\n",
    "    batch_size=N_TEST,\n",
    "    resolution=TEST_RESOLUTION_2,\n",
    "    shuffle=False,\n",
    "    seed=SEED + 2000,\n",
    "    worker_count=0,\n",
    "    enable_normalization=False,\n",
    ")\n",
    "\n",
    "# Collect training data\n",
    "X_train_list, Y_train_list = [], []\n",
    "for batch in train_loader:\n",
    "    X_train_list.append(batch[\"input\"])\n",
    "    Y_train_list.append(batch[\"output\"])\n",
    "\n",
    "X_train = np.concatenate(X_train_list, axis=0)\n",
    "Y_train = np.concatenate(Y_train_list, axis=0)\n",
    "\n",
    "# Add channel dimension: (N, H, W) -> (N, 1, H, W)\n",
    "if X_train.ndim == 3:\n",
    "    X_train = X_train[:, np.newaxis, :, :]\n",
    "    Y_train = Y_train[:, np.newaxis, :, :]\n",
    "\n",
    "# Normalize data for better training (compute stats from training data)\n",
    "X_mean, X_std = X_train.mean(), X_train.std()\n",
    "Y_mean, Y_std = Y_train.mean(), Y_train.std()\n",
    "X_train = (X_train - X_mean) / X_std\n",
    "Y_train = (Y_train - Y_mean) / Y_std\n",
    "\n",
    "# Collect test data at both resolutions\n",
    "test_batch_32 = next(iter(test_loader_32))\n",
    "X_test_32 = test_batch_32[\"input\"]\n",
    "Y_test_32 = test_batch_32[\"output\"]\n",
    "if X_test_32.ndim == 3:\n",
    "    X_test_32 = X_test_32[:, np.newaxis, :, :]\n",
    "    Y_test_32 = Y_test_32[:, np.newaxis, :, :]\n",
    "X_test_32 = (X_test_32 - X_mean) / X_std\n",
    "Y_test_32 = (Y_test_32 - Y_mean) / Y_std\n",
    "\n",
    "test_batch_64 = next(iter(test_loader_64))\n",
    "X_test_64 = test_batch_64[\"input\"]\n",
    "Y_test_64 = test_batch_64[\"output\"]\n",
    "if X_test_64.ndim == 3:\n",
    "    X_test_64 = X_test_64[:, np.newaxis, :, :]\n",
    "    Y_test_64 = Y_test_64[:, np.newaxis, :, :]\n",
    "X_test_64 = (X_test_64 - X_mean) / X_std\n",
    "Y_test_64 = (Y_test_64 - Y_mean) / Y_std\n",
    "\n",
    "print(\n",
    "    f\"  Training data ({TRAIN_RESOLUTION}x{TRAIN_RESOLUTION}): \"\n",
    "    f\"X={X_train.shape}, Y={Y_train.shape}\"\n",
    ")\n",
    "print(\n",
    "    f\"  Test data ({TEST_RESOLUTION_1}x{TEST_RESOLUTION_1}): \"\n",
    "    f\"X={X_test_32.shape}, Y={Y_test_32.shape}\"\n",
    ")\n",
    "print(\n",
    "    f\"  Test data ({TEST_RESOLUTION_2}x{TEST_RESOLUTION_2}): \"\n",
    "    f\"X={X_test_64.shape}, Y={Y_test_64.shape} <- UNSEEN resolution!\"\n",
    ")\n",
    "print(f\"  Normalization: Y_mean={Y_mean:.4f}, Y_std={Y_std:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c45c6cb",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## FNO Architecture\n",
    "\n",
    "The Fourier Neural Operator processes data in spectral space,\n",
    "which enables resolution-invariant predictions.\n",
    "\n",
    "Key components:\n",
    "- Lifting: Project input to high-dimensional feature space\n",
    "- Spectral convolutions: Learn in Fourier space\n",
    "- Projection: Map features back to output space\n",
    "\n",
    "The number of Fourier modes controls what frequencies the FNO can learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da17fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FNOWithEmbedding(nnx.Module):\n",
    "    \"\"\"FNO with grid embedding for positional encoding.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        modes: int,\n",
    "        hidden_channels: int,\n",
    "        num_layers: int,\n",
    "        grid_boundaries: list[list[float]],\n",
    "        rngs: nnx.Rngs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.grid_embedding = GridEmbedding2D(\n",
    "            in_channels=in_channels,\n",
    "            grid_boundaries=grid_boundaries,\n",
    "        )\n",
    "        self.fno = FourierNeuralOperator(\n",
    "            in_channels=self.grid_embedding.out_channels,\n",
    "            out_channels=out_channels,\n",
    "            hidden_channels=hidden_channels,\n",
    "            modes=modes,\n",
    "            num_layers=num_layers,\n",
    "            rngs=rngs,\n",
    "        )\n",
    "\n",
    "    def __call__(self, x: jax.Array) -> jax.Array:\n",
    "        \"\"\"Forward pass: grid embedding -> FNO.\"\"\"\n",
    "        # (batch, channels, H, W) -> (batch, H, W, channels) for embedding\n",
    "        x_hwc = jnp.moveaxis(x, 1, -1)\n",
    "        x_embedded = self.grid_embedding(x_hwc)\n",
    "        # (batch, H, W, channels) -> (batch, channels, H, W) for FNO\n",
    "        x_chw = jnp.moveaxis(x_embedded, -1, 1)\n",
    "        return self.fno(x_chw)\n",
    "\n",
    "\n",
    "print()\n",
    "print(\"Creating FNO model with grid embedding...\")\n",
    "\n",
    "model = FNOWithEmbedding(\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    modes=MODES,\n",
    "    hidden_channels=HIDDEN_CHANNELS,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    grid_boundaries=[[0.0, 1.0], [0.0, 1.0]],\n",
    "    rngs=nnx.Rngs(SEED),\n",
    ")\n",
    "\n",
    "n_params = sum(x.size for x in jax.tree_util.tree_leaves(nnx.state(model, nnx.Param)))\n",
    "print(\"  Architecture: FNO + GridEmbedding2D\")\n",
    "print(\"  Input channels: 1 (+ 2 grid coords = 3 after embedding)\")\n",
    "print(f\"  Fourier modes: {MODES}x{MODES}\")\n",
    "print(f\"  Hidden channels: {HIDDEN_CHANNELS}\")\n",
    "print(f\"  Spectral layers: {NUM_LAYERS}\")\n",
    "print(f\"  Parameters: {n_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5d47a2",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Training with Opifex Trainer\n",
    "\n",
    "We train ONLY on 32x32 resolution data. The model will later\n",
    "generalize to 64x64 without any retraining!\n",
    "\n",
    "Opifex's `Trainer.fit()` handles the training loop with:\n",
    "- JIT compilation for speed\n",
    "- Batching and shuffling\n",
    "- Validation evaluation\n",
    "- Progress logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46142c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "print(f\"Training on {TRAIN_RESOLUTION}x{TRAIN_RESOLUTION} resolution...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "config = TrainingConfig(\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    config=config,\n",
    "    rngs=nnx.Rngs(SEED),\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "trained_model, metrics = trainer.fit(\n",
    "    train_data=(jnp.array(X_train), jnp.array(Y_train)),\n",
    "    val_data=(jnp.array(X_test_32), jnp.array(Y_test_32)),\n",
    ")\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(\"-\" * 50)\n",
    "print(f\"Training completed in {training_time:.1f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7c14f9",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Evaluation: Zero-Shot Super-Resolution\n",
    "\n",
    "Now for the exciting part! We evaluate the model trained ONLY on 32x32 data\n",
    "on TWO different resolutions. The model has NEVER seen 64x64 data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33009be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_relative_l2(predictions, targets):\n",
    "    \"\"\"Compute relative L2 error.\"\"\"\n",
    "    pred_flat = predictions.reshape(predictions.shape[0], -1)\n",
    "    target_flat = targets.reshape(targets.shape[0], -1)\n",
    "    l2_diff = jnp.linalg.norm(pred_flat - target_flat, axis=1)\n",
    "    l2_target = jnp.linalg.norm(target_flat, axis=1)\n",
    "    return jnp.mean(l2_diff / (l2_target + 1e-8))\n",
    "\n",
    "\n",
    "print()\n",
    "print(\"=\" * 70)\n",
    "print(\"ZERO-SHOT SUPER-RESOLUTION TEST\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Evaluate at training resolution (32x32)\n",
    "X_test_32_jnp = jnp.array(X_test_32)\n",
    "Y_test_32_jnp = jnp.array(Y_test_32)\n",
    "predictions_32 = trained_model(X_test_32_jnp)\n",
    "rel_l2_32 = float(compute_relative_l2(predictions_32, Y_test_32_jnp))\n",
    "print(\n",
    "    f\"  Test at {TEST_RESOLUTION_1}x{TEST_RESOLUTION_1} (training resolution): \"\n",
    "    f\"{rel_l2_32:.2%} relative L2\"\n",
    ")\n",
    "\n",
    "# Evaluate at UNSEEN higher resolution (64x64) - zero-shot!\n",
    "X_test_64_jnp = jnp.array(X_test_64)\n",
    "Y_test_64_jnp = jnp.array(Y_test_64)\n",
    "predictions_64 = trained_model(X_test_64_jnp)\n",
    "rel_l2_64 = float(compute_relative_l2(predictions_64, Y_test_64_jnp))\n",
    "print(\n",
    "    f\"  Test at {TEST_RESOLUTION_2}x{TEST_RESOLUTION_2} (ZERO-SHOT, 2x): \"\n",
    "    f\"{rel_l2_64:.2%} relative L2\"\n",
    ")\n",
    "\n",
    "print()\n",
    "print(\"NOTE: The 64x64 test uses different samples, so high error is expected.\")\n",
    "print(\"True zero-shot super-resolution requires testing the same physics at\")\n",
    "print(\"different discretizations. See fno-darcy.md for advanced examples.\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb7a88e",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Visualization\n",
    "\n",
    "Compare predictions at both resolutions to see the super-resolution in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01b78bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "\n",
    "# Compute shared color scales for fair comparison\n",
    "idx = 0\n",
    "pred_32 = np.array(predictions_32[idx, 0])\n",
    "pred_64 = np.array(predictions_64[idx, 0])\n",
    "gt_32 = Y_test_32[idx, 0]\n",
    "gt_64 = Y_test_64[idx, 0]\n",
    "\n",
    "# Use ground truth range for consistent visualization\n",
    "vmin_32 = min(gt_32.min(), pred_32.min())\n",
    "vmax_32 = max(gt_32.max(), pred_32.max())\n",
    "vmin_64 = min(gt_64.min(), pred_64.min())\n",
    "vmax_64 = max(gt_64.max(), pred_64.max())\n",
    "\n",
    "# Row 1: Training resolution (32x32)\n",
    "axes[0, 0].imshow(X_test_32[idx, 0], cmap=\"viridis\")\n",
    "axes[0, 0].set_title(\"Input (Permeability)\")\n",
    "axes[0, 0].set_ylabel(\n",
    "    f\"Training Resolution\\n({TEST_RESOLUTION_1}x{TEST_RESOLUTION_1})\", fontsize=11\n",
    ")\n",
    "axes[0, 0].axis(\"off\")\n",
    "\n",
    "axes[0, 1].imshow(gt_32, cmap=\"RdBu_r\", vmin=vmin_32, vmax=vmax_32)\n",
    "axes[0, 1].set_title(\"Ground Truth\")\n",
    "axes[0, 1].axis(\"off\")\n",
    "\n",
    "im_pred_32 = axes[0, 2].imshow(pred_32, cmap=\"RdBu_r\", vmin=vmin_32, vmax=vmax_32)\n",
    "axes[0, 2].set_title(\"FNO Prediction\")\n",
    "axes[0, 2].axis(\"off\")\n",
    "plt.colorbar(im_pred_32, ax=axes[0, 2], fraction=0.046)\n",
    "\n",
    "error_32 = np.abs(pred_32 - gt_32)\n",
    "im = axes[0, 3].imshow(error_32, cmap=\"hot\")\n",
    "axes[0, 3].set_title(f\"Error ({rel_l2_32:.1%})\")\n",
    "axes[0, 3].axis(\"off\")\n",
    "plt.colorbar(im, ax=axes[0, 3], fraction=0.046)\n",
    "\n",
    "# Row 2: Zero-shot super-resolution (64x64)\n",
    "axes[1, 0].imshow(X_test_64[idx, 0], cmap=\"viridis\")\n",
    "axes[1, 0].set_ylabel(\n",
    "    f\"Zero-Shot 2x\\n({TEST_RESOLUTION_2}x{TEST_RESOLUTION_2})\", fontsize=11\n",
    ")\n",
    "axes[1, 0].axis(\"off\")\n",
    "\n",
    "axes[1, 1].imshow(gt_64, cmap=\"RdBu_r\", vmin=vmin_64, vmax=vmax_64)\n",
    "axes[1, 1].axis(\"off\")\n",
    "\n",
    "im_pred_64 = axes[1, 2].imshow(pred_64, cmap=\"RdBu_r\", vmin=vmin_64, vmax=vmax_64)\n",
    "axes[1, 2].axis(\"off\")\n",
    "plt.colorbar(im_pred_64, ax=axes[1, 2], fraction=0.046)\n",
    "\n",
    "error_64 = np.abs(pred_64 - gt_64)\n",
    "im = axes[1, 3].imshow(error_64, cmap=\"hot\")\n",
    "axes[1, 3].set_title(f\"Error ({rel_l2_64:.1%})\")\n",
    "axes[1, 3].axis(\"off\")\n",
    "plt.colorbar(im, ax=axes[1, 3], fraction=0.046)\n",
    "\n",
    "plt.suptitle(\n",
    "    f\"FNO Zero-Shot Super-Resolution: Train at {TRAIN_RESOLUTION}x{TRAIN_RESOLUTION}, \"\n",
    "    f\"Test at {TEST_RESOLUTION_2}x{TEST_RESOLUTION_2}!\",\n",
    "    fontsize=14,\n",
    "    fontweight=\"bold\",\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / \"super_resolution.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "\n",
    "print()\n",
    "print(f\"Saved: {OUTPUT_DIR / 'super_resolution.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc8edb7",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Summary\n",
    "\n",
    "In this example, we demonstrated:\n",
    "\n",
    "1. **Loaded** Darcy flow data with `create_darcy_loader()`\n",
    "2. **Created** an FNO with `FourierNeuralOperator` and `GridEmbedding2D`\n",
    "3. **Trained** at 32x32 resolution with `Trainer.fit()`\n",
    "4. **Evaluated** on unseen test samples\n",
    "\n",
    "**Key Opifex features used:**\n",
    "- `create_darcy_loader()` - On-demand PDE data generation\n",
    "- `FourierNeuralOperator` - Spectral-domain operator learning\n",
    "- `GridEmbedding2D` - Positional encoding for resolution invariance\n",
    "- `Trainer.fit()` - Standard training loop with JIT compilation\n",
    "\n",
    "**For better results**, see the advanced FNO example which demonstrates:\n",
    "- H1 loss (gradient-aware training)\n",
    "- Learning rate scheduling\n",
    "- True zero-shot super-resolution on matched samples\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- [FNO on Darcy Flow (Full)](../neural-operators/fno-darcy.md) - Advanced example with ~5% error\n",
    "- [Your First PINN](first-pinn.md) - Physics-informed approach (no data!)\n",
    "- [DeepONet on Darcy](../neural-operators/deeponet-darcy.md) - Alternative architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a33fc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "print(\"=\" * 70)\n",
    "print(\"Neural Operator example completed!\")\n",
    "print(f\"  Training time: {training_time:.1f}s\")\n",
    "print(f\"  Test error at training resolution: {rel_l2_32:.2%}\")\n",
    "print()\n",
    "print(\"KEY TAKEAWAY: FNO learns the Darcy operator from data!\")\n",
    "print(\"For better results, see the advanced examples with H1 loss.\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "py:percent,ipynb",
   "main_language": "python",
   "notebook_metadata_filter": "kernelspec,language_info,-jupytext.text_representation.jupytext_version,-jupytext.notebook_metadata_filter,-jupytext.cell_metadata_filter"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
