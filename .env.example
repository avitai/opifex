# Opifex Environment Configuration - GPU Enabled
# Copy to .env and source via activate.sh

# === Project Configuration ===
PROJECT_DIR="$(pwd)"

# === Python Version Detection ===
if [ -f "${PROJECT_DIR}/.venv/bin/python" ]; then
    PYTHON_VERSION=$("${PROJECT_DIR}/.venv/bin/python" -c "import sys; print(f'python{sys.version_info.major}.{sys.version_info.minor}')" 2>/dev/null)
else
    PYTHON_VERSION=$(ls -d "${PROJECT_DIR}/.venv/lib/python3."* 2>/dev/null | head -1 | xargs basename 2>/dev/null || echo "python3.11")
fi
VENV_CUDA_BASE="${PROJECT_DIR}/.venv/lib/${PYTHON_VERSION}/site-packages/nvidia"

# === CUDA Library Paths (venv-isolated) ===
# Filter existing LD_LIBRARY_PATH to remove old CUDA paths
if [ -n "$LD_LIBRARY_PATH" ]; then
    FILTERED_LD_PATH=$(echo "$LD_LIBRARY_PATH" | tr ':' '\n' | grep -v -E '(nvidia|cuda|cudnn|nccl|cublas|cusolver|cusparse|cufft|curand|nvjitlink)' | tr '\n' ':' | sed 's/:$//')
else
    FILTERED_LD_PATH=""
fi

NEW_CUDA_PATHS="${VENV_CUDA_BASE}/cublas/lib:${VENV_CUDA_BASE}/cusolver/lib:${VENV_CUDA_BASE}/cusparse/lib:${VENV_CUDA_BASE}/cusparselt/lib:${VENV_CUDA_BASE}/cudnn/lib:${VENV_CUDA_BASE}/cufft/lib:${VENV_CUDA_BASE}/curand/lib:${VENV_CUDA_BASE}/nccl/lib:${VENV_CUDA_BASE}/nvjitlink/lib:${VENV_CUDA_BASE}/cuda_runtime/lib:${VENV_CUDA_BASE}/cuda_nvrtc/lib:${VENV_CUDA_BASE}/cuda_cupti/lib:${VENV_CUDA_BASE}/nvtx/lib"

if [ -n "$FILTERED_LD_PATH" ]; then
    export LD_LIBRARY_PATH="${NEW_CUDA_PATHS}:${FILTERED_LD_PATH}"
else
    export LD_LIBRARY_PATH="${NEW_CUDA_PATHS}"
fi

export CUDA_HOME="${VENV_CUDA_BASE}"
export CUDA_PATH="${VENV_CUDA_BASE}"
export PATH="${VENV_CUDA_BASE}/cuda_nvcc/bin:${PATH}"

# === CUDA Performance Settings ===
export CUDA_MODULE_LOADING="LAZY"       # Faster startup, reduced memory
export CUDA_CACHE_DISABLE="1"           # Use JAX cache instead

# === JAX Platform Configuration ===
export JAX_PLATFORMS="cuda,cpu"
export JAX_ENABLE_X64="0"               # Keep 32-bit for performance

# === JAX Memory Management ===
export XLA_PYTHON_CLIENT_PREALLOCATE="false"
export XLA_PYTHON_CLIENT_MEM_FRACTION="0.85"  # Best practice: room for lazy-loaded CUDA kernels

# === JAX Compilation Cache (LOCAL - optimal for single-machine dev) ===
export JAX_COMPILATION_CACHE_DIR="${PROJECT_DIR}/.cache/jax"
export XLA_CACHE_DIR="${PROJECT_DIR}/.cache/xla"

# === XLA Performance Flags (AMD/NVIDIA compatible - no Triton flags) ===
# Note: Async collectives are enabled by default in JAX 0.9+
export XLA_FLAGS="--xla_gpu_strict_conv_algorithm_picker=false --xla_gpu_enable_latency_hiding_scheduler=true"

# === JAX CUDA Plugin ===
export JAX_CUDA_PLUGIN_VERIFY="false"

# === Logging (reduce noise) ===
export TF_CPP_MIN_LOG_LEVEL="1"

# === Development Settings ===
export PYTHONPATH="${PYTHONPATH:+${PYTHONPATH}:}${PROJECT_DIR}"
export PYTEST_CUDA_ENABLED="true"
export PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION="python"
